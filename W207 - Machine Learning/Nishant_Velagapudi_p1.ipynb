{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. Notice that we are splitting the data into training, development, and test. We also have a small subset of the training data called mini_train_data and mini_train_labels that you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (70000, 784)\n",
      "label shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the digit data either from mldata.org, or once downloaded to data_home, from disk. The data is about 53MB so this cell\n",
    "# should take a while the first time your run it.\n",
    "mnist = fetch_mldata('MNIST original', data_home='~/datasets/mnist')\n",
    "X, Y = mnist.data, mnist.target\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Create a 10x10 grid to visualize 10 examples of each digit. Python hints:\n",
    "\n",
    "- plt.rc() for setting the colormap, for example to black and white\n",
    "- plt.subplot() for creating subplots\n",
    "- plt.imshow() for rendering a matrix\n",
    "- np.array.reshape() for reshaping a 1D feature vector into a 2D matrix (for rendering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIIIAihYEwRBBAH/AXpOFkeyqsZEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f09706be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cast numpy arrays into single dataframe for easy sampling\n",
    "Viz_DF = pd.concat([pd.DataFrame(mini_train_data), pd.Series(mini_train_labels,name=\"Labels\")], axis=1)\n",
    "#track subplot index\n",
    "counter = 1\n",
    "for i in range(0,10):\n",
    "    #digit of interest\n",
    "    data_temp = Viz_DF[Viz_DF.Labels == i].sample(10)\n",
    "    for j in range (0,10):\n",
    "        #plot 10 examples\n",
    "        plt.subplot(10,10,counter)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.asarray(data_temp.iloc[j][0:len(Viz_DF.columns)-1]).reshape([28,28]),cmap='Greys')\n",
    "        counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Evaluate a K-Nearest-Neighbors model with k = [1,3,5,7,9] using the mini training set. Report accuracy on the dev set. For k=1, show precision, recall, and F1 for each label. Which is the most difficult digit?\n",
    "\n",
    "- KNeighborsClassifier() for fitting and predicting\n",
    "- classification_report() for producing precision, recall, F1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Neighbor Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.91      0.94       107\n",
      "        1.0       1.00      0.89      0.94       118\n",
      "        2.0       0.79      0.99      0.88        82\n",
      "        3.0       0.87      0.77      0.82        97\n",
      "        4.0       0.82      0.89      0.85        96\n",
      "        5.0       0.84      0.93      0.88        82\n",
      "        6.0       0.96      0.94      0.95       100\n",
      "        7.0       0.92      0.89      0.90       117\n",
      "        8.0       0.88      0.94      0.91        89\n",
      "        9.0       0.82      0.78      0.80       112\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1000\n",
      "\n",
      "Neighbors: 3, Correct: 878, Incorrect: 122, Accuracy: 0.878\n",
      "Neighbors: 5, Correct: 869, Incorrect: 131, Accuracy: 0.869\n",
      "Neighbors: 7, Correct: 865, Incorrect: 135, Accuracy: 0.865\n",
      "Neighbors: 9, Correct: 863, Incorrect: 137, Accuracy: 0.863\n"
     ]
    }
   ],
   "source": [
    "def P2(k_values):\n",
    "### STUDENT START ###\n",
    "#iterate over provided k values\n",
    "    for k in k_values:\n",
    "        #train\n",
    "        Model = KNeighborsClassifier(n_neighbors=k)\n",
    "        Model.fit(mini_train_data, mini_train_labels)\n",
    "        if(k == 1):\n",
    "            #special case, print classification report\n",
    "            print(\"Single Neighbor Classification Report: \")\n",
    "            print(classification_report(Model.predict(dev_data),dev_labels))\n",
    "        else:\n",
    "            #normal case, show dev set accuracies\n",
    "            actuals_preds = pd.concat([pd.Series(dev_labels,name=\"actual\"),pd.Series(Model.predict(dev_data),name=\"predict\")],axis=1)\n",
    "            corrects = len(actuals_preds[actuals_preds.actual == actuals_preds.predict])\n",
    "            incorrects = len(actuals_preds[actuals_preds.actual != actuals_preds.predict])\n",
    "            print('Neighbors: ' + str(k) + ', Correct: ' + str(corrects) + ', Incorrect: ' + str(incorrects) + ', Accuracy: ' + str(corrects/(corrects+incorrects)))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "P2(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We observe that the hardest digit to classify (from the single neighbor classification report) is 3. We have the worst f1 score for this digit - 4 is a close second. Presumably, most errors belong to classes 8 and 9 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Using k=1, report dev set accuracy for the training set sizes below. Also, measure the amount of time needed for prediction with each training size.\n",
    "\n",
    "- time.time() gives a wall clock value you can use for timing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 100, Correct: 626, Incorrect: 374, Accuracy: 0.626\n",
      "Train Size: 200, Correct: 767, Incorrect: 233, Accuracy: 0.767\n",
      "Train Size: 400, Correct: 832, Incorrect: 168, Accuracy: 0.832\n",
      "Train Size: 800, Correct: 860, Incorrect: 140, Accuracy: 0.86\n",
      "Train Size: 1600, Correct: 905, Incorrect: 95, Accuracy: 0.905\n",
      "Train Size: 3200, Correct: 927, Incorrect: 73, Accuracy: 0.927\n",
      "Train Size: 6400, Correct: 943, Incorrect: 57, Accuracy: 0.943\n",
      "Train Size: 12800, Correct: 958, Incorrect: 42, Accuracy: 0.958\n",
      "Train Size: 25000, Correct: 970, Incorrect: 30, Accuracy: 0.97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainingData</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.088079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.178155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.364815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.758747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1.667374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.927</td>\n",
       "      <td>3.277824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6400</td>\n",
       "      <td>0.943</td>\n",
       "      <td>6.606603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12800</td>\n",
       "      <td>0.958</td>\n",
       "      <td>13.500546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.970</td>\n",
       "      <td>25.920559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trainingData  Accuracy  Performance\n",
       "0           100     0.626     0.088079\n",
       "1           200     0.767     0.178155\n",
       "2           400     0.832     0.364815\n",
       "3           800     0.860     0.758747\n",
       "4          1600     0.905     1.667374\n",
       "5          3200     0.927     3.277824\n",
       "6          6400     0.943     6.606603\n",
       "7         12800     0.958    13.500546\n",
       "8         25000     0.970    25.920559"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def P3(train_sizes):\n",
    "    accuracies = []\n",
    "    times = []\n",
    "### STUDENT START ###\n",
    "    #iterate over training sizes\n",
    "    for train_size in train_sizes:\n",
    "        #train\n",
    "        pd_Train = pd.concat([pd.DataFrame(train_data), pd.Series(train_labels,name=\"Labels\")], axis=1)\n",
    "        sampled_data = pd_Train.sample(train_size)\n",
    "        Model = KNeighborsClassifier(n_neighbors=1)\n",
    "        Model.fit(sampled_data.loc[:, sampled_data.columns != 'Labels'],sampled_data.Labels)\n",
    "        #start timer before prediction\n",
    "        time1 = time.time()\n",
    "        predictions = Model.predict(dev_data)\n",
    "        time2 = time.time()\n",
    "        #quantify time spent\n",
    "        perf = time2 - time1\n",
    "        #compare predictions to actuals\n",
    "        actuals_preds = pd.concat([pd.Series(dev_labels,name=\"actual\"),pd.Series(predictions,name=\"predict\")],axis=1)\n",
    "        corrects = len(actuals_preds[actuals_preds.actual == actuals_preds.predict])\n",
    "        incorrects = len(actuals_preds[actuals_preds.actual != actuals_preds.predict])\n",
    "        accuracies.append(corrects/(corrects+incorrects))\n",
    "        times.append(perf)\n",
    "        #print results\n",
    "        print('Train Size: ' + str(train_size) + ', Correct: ' + str(corrects) + ', Incorrect: ' + str(incorrects) + ', Accuracy: ' + str(corrects/(corrects+incorrects)))\n",
    "    return pd.DataFrame(pd.concat([pd.Series(train_sizes,name=\"trainingData\"),pd.Series(accuracies,name=\"Accuracy\"), pd.Series(times,name=\"Performance\")],axis=1))\n",
    "### STUDENT END ###\n",
    "\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n",
    "P3_Output = P3(train_sizes)\n",
    "P3_Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a regression model that predicts accuracy from training size. What does it predict for n=60000? What's wrong with using regression here? Can you apply a transformation that makes the predictions more reasonable?\n",
    "\n",
    "- Remember that the sklearn fit() functions take an input matrix X and output vector Y. So each input example in X is a vector, even if it contains only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope coefficient of the regression is as follows: \n",
      "[  8.03348675e-06]\n",
      "Intercept of the regression is as follows: \n",
      "0.82025654658\n",
      "Predicted accuracy with a 60000 training data sample: [ 1.30226575]\n",
      "Predicted accuracy with a 60000 training data sample (with Logit Transformation): [ 0.99914008]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def P4():\n",
    "    AccuracyRegression = LinearRegression(fit_intercept=True)\n",
    "    AccuracyRegression.fit(P3_Output.trainingData.reshape(-1,1),P3_Output.Accuracy)\n",
    "    \n",
    "    #Logit transform accuracies to constrain outputs to domain (0,1)\n",
    "    #formula is f(x) = log(x / (1-x))\n",
    "    P3_Output['TransformedAccuracy'] = np.log(P3_Output.Accuracy / (1-P3_Output.Accuracy))\n",
    "    AccuracyRegression_tr = LinearRegression(fit_intercept=True)\n",
    "    AccuracyRegression_tr.fit(P3_Output.trainingData.reshape(-1,1),P3_Output.TransformedAccuracy)\n",
    "\n",
    "    #convert from logit transformed prediction to \"real\" probability\n",
    "    #formula is x = exp(f(x)) / (1+ exp(f(x)))\n",
    "    prediction_tr = np.exp(AccuracyRegression_tr.predict(60000)) / (1+ np.exp(AccuracyRegression_tr.predict(60000)))\n",
    "\n",
    "    print(\"Slope coefficient of the regression is as follows: \")\n",
    "    print(AccuracyRegression.coef_)\n",
    "    print(\"Intercept of the regression is as follows: \")\n",
    "    print(AccuracyRegression.intercept_)\n",
    "    print(\"Predicted accuracy with a 60000 training data sample: \" + str(AccuracyRegression.predict(60000)))\n",
    "    print(\"Predicted accuracy with a 60000 training data sample (with Logit Transformation): \" + str(prediction_tr))\n",
    "    \n",
    "P4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Linear regression will not be bounded to the probability domain, as our answer needs to be. We predict an accuracy of 1.28 for a sample of 60,000: which is unreasonable. We could transform the accuracy using the logit scale, which is bounded from 0 to 1. By transforming both the inputs and the outputs in this way, we observe that the accuracy predicted for a 60,000 sample traning data set is .9991."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a 1-NN and output a confusion matrix for the dev data. Use the confusion matrix to identify the most confused pair of digits, and display a few example mistakes.\n",
    "\n",
    "- confusion_matrix() produces a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97   0   0   0   0   0   2   0   0   0]\n",
      " [  0 105   0   0   0   0   0   0   0   0]\n",
      " [  4   4  81   4   0   0   0   4   3   2]\n",
      " [  1   0   0  75   0   3   0   3   1   3]\n",
      " [  0   2   0   0  85   0   3   0   0  14]\n",
      " [  2   0   0   9   0  76   0   1   1   2]\n",
      " [  1   1   1   0   1   0  94   0   0   0]\n",
      " [  1   4   0   1   1   0   0 104   0   2]\n",
      " [  0   2   0   5   0   2   1   0  84   2]\n",
      " [  1   0   0   3   9   1   0   5   0  87]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nteAxTbw1CwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f11f61cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P5():\n",
    "#fitting on mini train data\n",
    "    OneNeighbor_confusion = KNeighborsClassifier(n_neighbors=1)\n",
    "    OneNeighbor_confusion.fit(mini_train_data,mini_train_labels)\n",
    "    #zip together predictions and actuals\n",
    "    PredictionsMatrix = pd.concat([pd.DataFrame(dev_data),pd.Series(dev_labels,name=\"actual\"),pd.Series(OneNeighbor_confusion.predict(dev_data),name=\"Predictions\")],axis=1)\n",
    "    #confusion matrix calculation\n",
    "    print(confusion_matrix(PredictionsMatrix.actual,PredictionsMatrix.Predictions))\n",
    "    dev_data_pd = pd.DataFrame(dev_data)\n",
    "    errorSample = dev_data_pd[((PredictionsMatrix.actual == 9) & (PredictionsMatrix.Predictions == 4)) | ((PredictionsMatrix.actual == 4) & (PredictionsMatrix.Predictions == 9))][0:783].sample(4)\n",
    "    counter = 1\n",
    "    \n",
    "    for j in range (0,4):\n",
    "        #plot 10 examples\n",
    "        plt.subplot(2,2,counter)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.asarray(errorSample.iloc[j]).reshape([28,28]),cmap='Greys')\n",
    "        counter += 1\n",
    "P5()\n",
    "#we see that 4 and 9 are most often confused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian -- that is, the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur by just using the 8 neighboring pixels: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values. Try applying your blur filter in 3 ways:\n",
    "- preprocess the training data but not the dev data\n",
    "- preprocess the dev data but not the training data\n",
    "- preprocess both training and dev data\n",
    "\n",
    "Note that there are Guassian blur filters available, for example in scipy.ndimage.filters. You're welcome to experiment with those, but you are likely to get the best results with the simplified version I described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blur Training Only Prediction accuracy: 0.853\n",
      "Blur Dev Only Prediction accuracy: 0.261\n",
      "Blur Both Prediction accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "def GaussianBlur(img):\n",
    "    #pixel of interest gets full weight\n",
    "    #directly adjacent pixels get 1/2 weight\n",
    "    #diagonals weighted as 1/sqrt(8) due to increased distance to center of pixel of interest (pythagorean theorem if both sides are of length 2)\n",
    "    shape_img = img.reshape(28,28)\n",
    "    new_img = []\n",
    "    for width in range(0,28):\n",
    "        for height in range(0,28):\n",
    "            #count pixels used in average, tally total pixel \"darkness\" using surrounded pixels and pixel of interest\n",
    "            counter = 0\n",
    "            value = 0\n",
    "            value += shape_img[width, height]\n",
    "            counter += 1\n",
    "            \n",
    "            if (height - 1 >= 0): #top\n",
    "                value += shape_img[width, height-1]/2\n",
    "                counter += 1\n",
    "            if (width - 1 >= 0): #left\n",
    "                value += shape_img[width-1, height]/2\n",
    "                counter += 1\n",
    "            if (width + 1 < 28): #right\n",
    "                value += shape_img[width+1, height]/2\n",
    "                counter += 1\n",
    "            if (height + 1 < 28): #bottom\n",
    "                value += shape_img[width, height+1]/2\n",
    "                counter += 1\n",
    "            if ((height - 1 >= 0) & (width - 1 >= 0)): #top-left\n",
    "                value += shape_img[width-1, height-1]/np.sqrt(8)\n",
    "                counter += 1\n",
    "            if ((height - 1 >= 0) & (width + 1 < 28)): #top-right\n",
    "                value += shape_img[width-1, height-1]/np.sqrt(8)\n",
    "                counter += 1\n",
    "            if ((height + 1 < 28) & (width - 1 >= 0)): #bottom-left\n",
    "                value += shape_img[width-1, height-1]/np.sqrt(8)\n",
    "                counter += 1\n",
    "            if ((height + 1 < 28) & (width + 1 < 28)): #bottom-right\n",
    "                value += shape_img[width-1, height-1]/np.sqrt(8)\n",
    "                counter += 1\n",
    "            new_img.append(value/counter)\n",
    "    return(np.asarray(new_img))\n",
    "\n",
    "\n",
    "def P6():\n",
    "    blur_mini_train_data = np.apply_along_axis(GaussianBlur, 1, mini_train_data)\n",
    "    blur_dev_data = np.apply_along_axis(GaussianBlur, 1, dev_data)\n",
    "    \n",
    "    #processed training, not dev\n",
    "    OneNeighbor_confusion = KNeighborsClassifier(n_neighbors=1)\n",
    "    OneNeighbor_confusion.fit(blur_mini_train_data,mini_train_labels)\n",
    "    blurTrain_RawDev = pd.Series(OneNeighbor_confusion.predict(dev_data),name=\"BlurTrain_Predict\")\n",
    "    \n",
    "    #processed dev, not training\n",
    "    OneNeighbor_confusion = KNeighborsClassifier(n_neighbors=1)\n",
    "    OneNeighbor_confusion.fit(mini_train_data,mini_train_labels)\n",
    "    RawTrain_BlurDev = pd.Series(OneNeighbor_confusion.predict(blur_dev_data),name=\"BlurDev_Predict\")\n",
    "    \n",
    "    #process both dev and training\n",
    "    OneNeighbor_confusion = KNeighborsClassifier(n_neighbors=1)\n",
    "    OneNeighbor_confusion.fit(blur_mini_train_data,mini_train_labels)\n",
    "    BlurTrain_BlurDev = pd.Series(OneNeighbor_confusion.predict(blur_dev_data),name=\"BlurBoth_Predict\")\n",
    "    \n",
    "    PredictionsMatrix = pd.concat([pd.Series(dev_labels,name=\"actual\"),blurTrain_RawDev,RawTrain_BlurDev,BlurTrain_BlurDev],axis=1)\n",
    "    return PredictionsMatrix\n",
    "\n",
    "GaussianPredictions = P6()\n",
    "\n",
    "print(\"Blur Training Only Prediction accuracy: \" + str(len(GaussianPredictions[GaussianPredictions.actual == GaussianPredictions.BlurTrain_Predict])/1000))\n",
    "print(\"Blur Dev Only Prediction accuracy: \" + str(len(GaussianPredictions[GaussianPredictions.actual == GaussianPredictions.BlurDev_Predict])/1000))\n",
    "print(\"Blur Both Prediction accuracy: \" + str(len(GaussianPredictions[GaussianPredictions.actual == GaussianPredictions.BlurBoth_Predict])/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We can see that the best accuracy is attained when blurring both the training data set and the dev training set. We achieve extraordinarily poor accuracy when blurring the dev set only but leaving the training set untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Fit a Naive Bayes classifier and report accuracy on the dev data. Remember that Naive Bayes estimates P(feature|label). While sklearn can handle real-valued features, let's start by mapping the pixel values to either 0 or 1. You can do this as a preprocessing step, or with the binarize argument. With binary-valued features, you can use BernoulliNB. Next try mapping the pixel values to 0, 1, or 2, representing white, grey, or black. This mapping requires MultinomialNB. Does the multi-class version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of binarized data: 0.815\n",
      "Accuracy of ternary data: 0.795\n"
     ]
    }
   ],
   "source": [
    "def castToTernary(dataPoint):\n",
    "    #map pixel value to 0,1,2\n",
    "    if(dataPoint == 0):\n",
    "        return 0\n",
    "    elif (dataPoint < .5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def P7():\n",
    "### STUDENT START ###\n",
    "    BernoulliNB_digits = BernoulliNB(binarize=0.0)\n",
    "    BernoulliNB_digits.fit(mini_train_data,mini_train_labels)\n",
    "    \n",
    "    predictionsDF = pd.concat([pd.Series(dev_labels,name='Actual'),pd.Series(BernoulliNB_digits.predict(dev_data),name='predictions')],axis=1)\n",
    "    print(\"Accuracy of binarized data: \" + str(len(predictionsDF[predictionsDF.Actual==predictionsDF.predictions])/1000))\n",
    "    \n",
    "    ternary_mtd = np.array([castToTernary(point) for point in np.nditer(mini_train_data)])\n",
    "    MultiNB_digits = MultinomialNB()\n",
    "    MultiNB_digits.fit(ternary_mtd.reshape(1000,784),mini_train_labels)\n",
    "    \n",
    "    ternary_devData = np.array([castToTernary(point) for point in np.nditer(dev_data)]).reshape(1000,784)\n",
    "    predictionsDF = pd.concat([pd.Series(dev_labels,name='Actual'),pd.Series(MultiNB_digits.predict(ternary_devData),name='predictions')],axis=1)\n",
    "    print(\"Accuracy of ternary data: \" + str(len(predictionsDF[predictionsDF.Actual==predictionsDF.predictions])/1000))\n",
    "\n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We can see that the binarized NB model outperforms the ternary model by 2 percent in terms of accuracy. This could be due to the fact that the dev set has different uses of \"grey\" than the training set. It could also be that the choices of boundaries for grey versus black are set improperly: in practice, I would iterate over different definitions of grey and black to see what optimizes accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Use GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) in a Bernoulli NB model. What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n",
    "\n",
    "- Note that GridSearchCV partitions the training data so the results will be a bit different than if you used the dev data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "def P8(alphas):\n",
    "    BernoulliNB_digits = BernoulliNB(binarize=0.0)\n",
    "    GridSearch = GridSearchCV(BernoulliNB_digits,param_grid=alphas)\n",
    "    GridSearch.fit(mini_train_data,mini_train_labels)\n",
    "    return GridSearch\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = P8(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          parameters  mean_validation_score  \\\n",
      "0     {'alpha': 0.0}                  0.803   \n",
      "1  {'alpha': 0.0001}                  0.820   \n",
      "2   {'alpha': 0.001}                  0.820   \n",
      "3    {'alpha': 0.01}                  0.820   \n",
      "4     {'alpha': 0.1}                  0.821   \n",
      "5     {'alpha': 0.5}                  0.819   \n",
      "6     {'alpha': 1.0}                  0.812   \n",
      "7     {'alpha': 2.0}                  0.810   \n",
      "8    {'alpha': 10.0}                  0.775   \n",
      "\n",
      "                               cv_validation_scores  \n",
      "0  [0.843195266272, 0.768768768769, 0.796352583587]  \n",
      "1  [0.849112426036, 0.795795795796, 0.814589665653]  \n",
      "2  [0.849112426036, 0.792792792793, 0.817629179331]  \n",
      "3  [0.855029585799, 0.792792792793, 0.811550151976]  \n",
      "4  [0.855029585799, 0.798798798799, 0.808510638298]  \n",
      "5  [0.849112426036, 0.804804804805, 0.802431610942]  \n",
      "6  [0.837278106509, 0.801801801802, 0.796352583587]  \n",
      "7  [0.834319526627, 0.801801801802, 0.793313069909]  \n",
      "8  [0.795857988166, 0.753753753754, 0.775075987842]  \n",
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(nb.grid_scores_))\n",
    "print(nb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We observe that an alpha of 0.1 has the best validation score. An alpha of 0.0 gives a mean validation score of .803. The LaPlace smoothing parameter adds a constant to all variable observations. In this case, if a particular pixel has never been black, the model may put undue weight on a black instance of this pixel. Larger smoothing values \"reduce\" the probably effect of novel observations. An alpha of 0.0 indicates no smoothing at all - it's unsurprising that this has a relatively high accuracy, since the digits are mostly clean and generally centered in the image renderings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) Try training a model using GuassianNB, which is intended for real-valued features, and evaluate on the dev data. You'll notice that it doesn't work so well. Try to diagnose the problem. You should be able to find a simple fix that returns the accuracy to around the same rate as BernoulliNB. Explain your solution.\n",
    "\n",
    "Hint: examine the parameters estimated by the fit() method, theta\\_ and sigma\\_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using GNB, untransformed: 0.621\n",
      "Accuracy using GNB, white noise added: 0.79\n"
     ]
    }
   ],
   "source": [
    "def GaussianNoise(value,mean,variance):\n",
    "    #assumes we're being passed a 784 dimensional array\n",
    "    #add gausian noise with specified characteristics\n",
    "    return value + np.random.normal(loc=mean,scale=variance,size=len(value))\n",
    "\n",
    "def P9():\n",
    "\n",
    "### STUDENT END ###\n",
    "    #train model with no adjustment\n",
    "    GNB_digits = GaussianNB()\n",
    "    GNB_digits.fit(mini_train_data,mini_train_labels)\n",
    "\n",
    "    predictionsDF = pd.concat([pd.Series(dev_labels,name='Actual'),pd.Series(GNB_digits.predict(dev_data),name='predictions')],axis=1)\n",
    "    print(\"Accuracy using GNB, untransformed: \" + str(len(predictionsDF[predictionsDF.Actual==predictionsDF.predictions])/1000))\n",
    "    \n",
    "    #train model with adjustment\n",
    "    GNB_digits = GaussianNB()\n",
    "    GNB_digits.fit(np.apply_along_axis(GaussianNoise, axis=1,arr=mini_train_data,mean=0,variance=.10),mini_train_labels)\n",
    "\n",
    "    predictionsDF = pd.concat([pd.Series(dev_labels,name='Actual'),pd.Series(GNB_digits.predict(dev_data),name='predictions')],axis=1)\n",
    "    print(\"Accuracy using GNB, white noise added: \" + str(len(predictionsDF[predictionsDF.Actual==predictionsDF.predictions])/1000))\n",
    "    \n",
    "    return GNB_digits\n",
    "### STUDENT END ###\n",
    "\n",
    "gnb = P9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(mini_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The GaussianNB model is intended for real-valued features, our images are composed of discrete greyscale values in the pixels. There are 256 unique pixel values observed. This leads to the sigma and theta results observed. The solution is to add Gaussian noise to every pixel value, effectively ensuring these observations are indeed continuous. The GaussianNoise function I defined above does this - different variances provide a different performance. I see a somewhat optimized accuracy using a mean of 0 and a variance of 10 in the gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) Because Naive Bayes is a generative model, we can use the trained model to generate digits. Train a BernoulliNB model and then generate a 10x20 grid with 20 examples of each digit. Because you're using a Bernoulli model, each pixel output will be either 0 or 1. How do the generated digits compare to the training digits?\n",
    "\n",
    "- You can use np.random.rand() to generate random numbers from a uniform distribution\n",
    "- The estimated probability of each pixel is stored in feature\\_log\\_prob\\_. You'll need to use np.exp() to convert a log probability back to a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztneFyLDmIrMs39v1f2ffPVizDgEQm\ndKtck1/EieNulxCSEALsln9+f38vIYQQ7+H/nVZACCHELHLsQgjxMuTYhRDiZcixCyHEy5BjF0KI\nlyHHLoQQL0OOXQghXoYcuxBCvAw5diGEeBly7EII8TL+55ud/fz8QPcX/P7+Xj8/P/fXP4wMJ++o\njHs8v7+/P9M62LliZWT6dmRM6CEZuIwn6CAZn5FR4RER+31fjb+3BnRU/2jfuQOne39O1h4dDwIi\nm5XJzotfmxMy2PbWNqOvO0zMJypjagxs/9N6eB2qsrr6e1lezuk7uL4asUf4CbYTUnFW2YT+b2Rc\ndnj2WZMlwM7YtmX0sG3RufDtI6pzap9jHeI99kgOsraRLsi6VuRm+PVD19L26ecDkZnNBTOPfk2q\nNrpaP1RO9AyzX/1embBvdq+htrmSxepzc9SxT5xq1piiSUYMLXMCzELf8piNY3VhjSxzIlUZ3Wiu\n48RsGzuHrF6RA2DbexmII1kdMtX2q0Bmp//KoaHOIzocbF+7dtE+Qeke2pl93v9PO+jqs+z+tzyi\nFGONgokUJyZiov2tf2TcSDRk2yBG7zMOP59V7Dgqekbto0OGLRt42Wh7u7aofVmH2JnPyB6sXKR9\nR4/risuWu7mI9Ld6MIdEp3zo58C+rsznSgc0E7Jy2AzfyukGMtd1MGKvpLdMempf7yKHLNpnT++V\nA6kaG3vArOazmjFYWXc7dBzWWa3mtDoe1rB9e3Z+V3aJ6BatAbMezGG322vVw3r1PTTzyOTvbGx1\nwCG2ZfvsHDAWdG2zgHRCn2MRe5Ye3t+ryogmJHJMlQg6e29naFm0Yr+3O2Sy71ejs0oEWI3KVo6r\nelhGuqBO/dbFR5oVR5JtlCxqzfTI1hBNtzOHWtGjsunRtUVZ6VpZEx9IWaadWgXmkMx8CBNYVvtk\n5+OYY/cbv+IAIxlZNLNyuJZd6oNsuux7lWh9FVVXo6Hd99AUNXLKlchtNddVpxzZQzWqu5/ZrWV1\nXaJ1rDqAarmlQlYOQSPV3XsR1ey50t6vX+Vw83KicTOZlKeSVdzPrfZrZT/u9OhwpBQTlTjQtHuX\nwqAbqRKtsqyiFfv9yPgn9GDk7HRF+6ocsrtnJ0ofkdNF9IgOi0rEtgoeqhnZSkd2Tar7JHLGvt+u\n86/oYPvJbKMypiyDyr6HsNtvUb++DRLERByJ2FcR3XVxNelKhObxE+nLCCtdrQwb2SELGr2fpf47\nsswny2iicUTPVTMfr4udy2q7u7+oXMJu3FX6XLUxPxbbnnUiVR1sCSSbC8ahrvbNThfbL7q+FZ0y\nIrvqHpLRPmGI5pOVFfkhlGM/PF2l20ha5g0za7tKraI+d1G212EVbbObv9K/bZ+9F2UEvt/se1aX\nKtkBy0amXedRXctVe4bMxlEZXpdJh1rdb1ngwOgQ6dKJkFkHuDpwERnR1+iejb7uzMnxX3eMJgMZ\nkHVKq+hll3L7vhFHEB0wDJ25WKXJWQkgkl95JiPql1nTLDKuHOCZzoxzZ2wperZqoyjIOOyzka1X\nyLKgKtnY0fmw9hxld4gc1olmc4isb7QuuwCrytEPKE0ZuJfFOkXW4P2z3liQ0lKH3aZhIma0HBRl\nAOymWb3PRv9TujAwc5JlVIxenTWxbbpzMm3rU2OZcu6sLtXXFY5H7KfpRtkREwvzFE46wv8yE+n4\nFJ/YI2/n9Jz9nFZACCHELP/5iF0IId6GHLsQQrwMOXYhhHgZcuxCCPEy5NiFEOJlyLELIcTLkGMX\nQoiX8dVPnv485K98P0HGE3R4qwzm7pCnjoWV8fPz89u4Q+Ux41jJqIzvxFgivSb1qPCoiL16YdLq\noq/J+1om2rPypj449oQPoE3qgFxYFbX7ti6T7bK2mTzicIOfn9hzLFN3NF3XrH1MfFq4q8cjHHt0\nudNqYKuJs4uNTI79CHfHWCaMbaItcmHWp3TJ9OnIWK191el31mfiRsLOxrcXV3VueIzm4FvXR1j9\nK+uwCuTsfUwdJp0xo4ufi64+j3Ds0d0qHaPpXuKFtkXkfqqNb9u5ue5mMhKbcAITF6lll2qhurBM\nRpin7pHpzgN60dzqUrgJG0dsbCXH6oW28zbZzfwf4dgtUycnu3GnU3b29O7qMHmJVEePiZsAp6Ky\nbkSFvJ9hx3Iqs5tYk8whnYSZD+QG1k/o4O0h0wXV7ejfPF297jCRIp86YCbTsScwWf+coBrVr9p1\n7MQ7xInsDO1/8tCfoJM9deVM0/U9UwfMMceeKX/yh41Tdemb06nyFBMb72RN2zNR0mF4wiHXHdvJ\nH5ZabNbA8IkfpnfkTevxiFLM6R9ITco7vfGegt94J9d1qoTTZXptJ0tKVaZKLxNr0gkOuwdD1t9T\n9u8jHPtNZ1KesHknFvhpafIEE2N5iozTWMfa+cH8VOAS7ZuqY+2wGgfitCcymM6c3hnQ9M8qjjr2\n6dpp57cdJurr3cWZLgV19Jjs/ykp88lodfK3Ybrz2f2Ns10Aw/4cg9UpoqLDRNS++k0WhFeWYna/\n6rOj+xsG9wJP1R8nDpcJpqIiBL8G3YOuG2HathO/4jjxG0KdH6gz7X3bbgmn+4Pfk7+q6TldVop+\n62vCyR917JmRoZNtDQ2ZlG9Exd9KCe++7KbpHHSsE4rW4GSJrauDnYepunDnV+JO4fcXG0x559X9\nzZ4OU2WQSfueKsl89a6YiJNRalR+mV5gxjFO9H8yIpqYy4n2U0zbxsQPkk85ou5cTP+s5NQ8TMma\n2iueR5Riujzh16+EEIJl/FeU5RSFEOJdvCJiF0II8X/IsQshxMuQYxdCiJchxy6EEC9Djl0IIV6G\nHLsQQrwMOXYhhHgZX/3k6c8f+2vjOxk7vbPv//7vX5Gf0OFpMtB7QJ48lr8s4wk6vE3GdV2/jftx\nJvXYcvxKAX+jIegUruv69yVejBx/H0f1drhMp6qMTJ9dP59oG7VH5fjnutcQd+eic3eNb9+5LM7K\n6tgmY6eRDmjbSFZHRnefdO2U0SOy7Wg9WD+26gvl+LW90c1m6MVZUVv2cqJIbrW9v40QGcvExUZR\ne1SH64rvr+hcKIbqEfXJXI7k7xRB13Xi4q+oP8RGs4Mye72T5R3QiUvzojGwF6Odwgek0deInNfd\nFbOLpnYTdW/YicuAdjfPrXSxOrBZx/0anYNIh+h1VQYbXVb12mE3ejQXjIPpHpzRIYeuy0T24fvt\n2BrKKkOtzIXtv7tnJ7MOK6diJ1EA1PU/9/oyQWXE0T9mHU1Mx/i7k+sNrlvWQMs52eGAlA5sG59F\noPpOGe6tG6KHdYZsBpXJnLAp9tCbzIJYOahdVOTtZPlnuo4rOyyrB7g/ZLzsSt9WTqVdJottu+L4\nH7OeOqG87AlHxLTxZaFJY97hy0BdOfcYOrI6aeqtC3PAZgcjMyZfwqjqcPfn9WA2c5RJdbNb1rmv\nnOKqb/96yq6YLDVyzj6IYEplHSb9w9GIPUvj0Mnycth6brTACN1DKtIfPRimojHrPDqb/4aNuqPn\nK+l/dKAw6buXg85tdKhEOlX08Ac3um+yQ4056DIdKnSDhVsHK2+iFJLJr7AqHyJ6ZP2j83U8Yvfv\nobWuyBl3JqXj3CMdqqmajcYyKhv3fm7i9GcOyixTQYw+O9T8IbOS5R2Pn5uqHlG0jmYhfvyoU/d9\n+f67h3j18F4FY2y/9v8q9oDKso+q78jWBtErOihRvN/pzu/RiN3+f3/dOc19qnozXb+K+vV9e6Pr\nyK4SGTm7aVgn5uVY3aaiKuRwWMnajWd1CFR0WWUbLKvIsprBoCW71cGGli4iOcyc2KzB62n7iMj6\nQ/RZPTtRcejKPP5bMVHtLfveqq13ap0IswuTZq+eR7OXSFZVhv165dBWsO3889EBU53bbD2t3GoG\nxK7LlE1lffi5qc57FmFW+8lAo/67DVMay+YetbPM/1Sde/azAzRAXdkrw2M+oJQZ5WrAWa2PcdRZ\nOlaRxdY8V/KQ/nd6VXXJnChaU44iPKQEsooCs6zIEmVsfn1ZXZB03duo12XXPtIhmptdScp+XZ0z\nFLZM6MeE2hrTzuvV2W9ZJoSQ7dPOuI459qoxIs8wk+AdhZdTldnZLJW52MnKvocaSuQ02Q3nX7MG\nn41hN+bIiSJjWdkBs64rB78iyjCYucx0YuRE763mNhovOx7f38QYUD0ym2Sd8ZQ/uzleipmAWdxM\nziSTqfi3xhc5gOl5QZhyRJmzr4JG2Ss90IPu5PxbKplr5fud/foUu7RM6sSWXjyvcOxdnmIgGT46\nED3Q9Z7+GYwQGVN29iNHIYQQ70IRuxBCvAw5diGEeBly7EII8TLk2IUQ4mXIsQshxMuQYxdCiJch\nxy6EEC/jq1cK/Dzkr40/QcaUDuyHZ540F5IxL0O28V4ZFV4VsXc/bDXxYa1v65DdURP9/1/EXzj1\nFFmTcna3Mn6Cjm35NuhNiJmcDlPj6PQ9OZ7H3O5oYW9Xs68rFz5F32dvaIz0qF465S8hY+8l8ZcR\nRXpVZGSwc4HKiMbRkZPdJoi29fp0bwJEbCOSccthrkjwMqK+du2ngxh0bSIZE2uLrAkrw+vs57R7\nKB//QxvXFV8t6p/J2keGjV6ydMvr3qDnZbEbwOuBtM8OyqouzNxFMjrzGG2aWybiyOy4yZLEP/rO\n9GRkVdfU20F2kdZur9h/kfxKEJQdKtWx7A78ikO1Okf7vqKLn0PGPq2/yPxPlWhdu4fm8T+NF0VU\n/plV+0geqkPlBK7IihYaNZwo4mYML9v0aPaA6u/1ztpWN6A1dDZl9/2hfdv3Ov369yblrUpyK0cY\nfR1h18GvCZtVWtmIQ86eZfZKJK+qy1TpxM5rx8Ytx2vsndTSOpHOxKwWiTl9rQ7VrAN1PBF+w7Ey\nIh2revkD2+qCOsluaarTZkoP71SnUu2KLtl8W13QbJB16He/WXtkz0851Sy7Rde2a59Wn4mM+boe\n4Nivi7+WduWEGB3YaL3Tp//6030yoM4oc+asE2HlTNQtpxxJlrpPyK0+x5YGb2xk2ZVj5xQ5YLJM\n/wbVaWr+2cMyk/dnSzE33lhuUAcfta/IyE5bNlJn2to+7VjYDeTbM6UUq0/0PaRdJ8qO1pUpbXkd\nmfb2PUaWd2Rs1JvJ3bXLxsLQmdeJvbIr9VWxdtaZi+mA7HURe3fTRI5x1Wa1cdlUc9V39bCZqr9W\n+7yJ9K/M58oBZyWnHVkJB43u7q/ZaNmnyOwBETkRJPiwdsk6pG7G4Ptix2HbIWPwc9HN0u3/t3x2\nv3RsZLL6cF0PcewRaJSJbpZKv+gCR6llthEsvh9vtJUDyj/HRu1ZOapz0LDRULQWTHSYpcnVec2e\nR0tC9jUyr5FdV8sYNjvI5EY6rojmBQmivF2sdFzpHB3WVf27a5LJRYPCVabb4ejvsWc1MmRSrHGg\n7Ay7ukgrPXbto83q+9/JiDa+1QU1MnQMkRx/0CEGn60lss5+XtmDZXWgVGXasa/mgj0oqpmUtwe/\nPpU+vZ1XbMzbAzqGTBfftmIfkS4dPfw+Y2x8uoxzXYcj9l26vxtwtkBoarfatNWIij3xowOhEuV7\nspQW1SXrn4mUrV5Mept9D4lyo7aok89kVbB2sXOk1XH5MgaKt1M0a8gysZ2zXK0JSieztv8z+9YH\nW3YPV209GzeaYWcc/+Rp5Nyz16v27ERMpT5RmolsvGzsTHsfwVSiqV2/zAGR9cHIYORMrO1T7CuS\n9c0DKnvWOzhGBsruoGBkTbRhbCUbg7d1NLB6bI39r7I6qE7wJh18ZiRm6MznE+zrjbQPcW0SIYR4\nF4rYhRDiZcixCyHEy5BjF0KIlyHHLoQQL0OOXQghXoYcuxBCvAw5diGEeBlf/eTpz0P+yvcTZDxB\nB8l4r4wn6HDLaFx98Jj5fJKMCorYhRDtT/Ou2k99OlUfpqzzSMfOLqC/cOmTxjpN1tfkGDrzWm2/\neoaR49cTkbGT/5T1RW91jG7frM5pZA/MjYT+PeZSNC+zcunf6rmpPc/ImPY9XjbK4xw7Mgg/mdFN\niUiffmHQu0myTeO/FxEZbcc4/BiYtla3qgz7bGboiBPwsqP3K+2jtWV0sDKQeY0uRkOcor9sy+pQ\nvSExeg6Zi+xSKnQeurYejSF6v0K2jsz6WttHD8rowOuM69jtjtbpZBt2Z3Q7A0ENNrrSs3OrH3pI\n+es/rS6MHPu6IiubO/Rg8GNHHXImA12PqF9k86ER7U5WNAZELnvYRm1Zov3KjMEfMshBm60hk3lk\nwRuTwTA3S9pxdOVZjkXsFcOsbLzVRmENv/I++hxiKD4yq7bb/b9jFVVG3490iOR1UlO/8ZiMzh6Y\njJzsefbQte2rcxMFHYwOnVsDs4MO3SM7O1sROXX0kIvmoHtwTxz80dcsxxz7hPLeyH36UnWmUaaA\nRnWRLlW6JYOKYTPRMhsdR+uB4p0ImsFEc4o6scgJZ69XcrIU249tNw7b9+r7mYzoIEHa2/5Z526f\nZcoN2V5B9IjWg/EbN1F2jB5W9/8TfvG6HlRjjwbUGWTFwUbGifYZLcbudSQjk1c9KLxBesNDjDXr\nc8roqnrY1xN9V7MP+/3swK4cfOjhuNJjdVgyWWV3b7HlJA9TpvO6WFndDIZxyFEmWNFlt986HC3F\nZDVQVI5vV43wds9UdbFyMn1WTG6USC/kefuP7bMrw8uaaN9xstm6Vg5bG5V/ao2rhxTazrdfBUHV\nzPJ0ycPqEWUeKx1Rh488m/3Pcjxij6LV1eBWkzsROUR0aohVg7//9yUYdKHZ9Hglb9JRI31eFxYB\nZX1NONR7TXb2udLDvseUuvzzTPupw3Zqr1XKUZkO2WsUX6pa9eu/jvpmSjC27cThddyx+0ndpWbZ\nRrnb7BZnBRtxR3og7TIZdixojbx78k+WPpiN59uy5ZgoTWbwhy8zHlb/lR6MPNuWsQ8bfEwd9p09\ny9AZv5cxpdNUFnddD/jh6USqbOVVa59VeR09JmAddGc+owOWGY+VwfzswveLOjNfBunM5f0/O68T\nGRjyPQ/7M6zomSijYuhkUmjgEx2QUeDRyQpZu7KvO4Gp5djvse8WFZ0kdkG6sibbTsuYckIdnSbG\n0h1Hl4l56LbtyvnEwcLqMgGaQX1Sz6g8h+qElvh2HC/FfItv/UbHkzi16SaJ6qkndfG82a7+ytim\ngw42u+zoNG3XP39l8YQQQtT4z0TsQgjxX0GOXQghXoYcuxBCvAw5diGEeBly7EII8TLk2IUQ4mXI\nsQshxMv46idPfx7yV76fIOMJOkjGe2U8QQfJ+IyMCorYX4I+aPbfYXKt/4LdfErHp419Up9jd8VY\nurekrW6IRO5MWV3fibTPqF5OxvSf3TvRvcWvc+fMJ2/Qq8pd3RiK2kZ2MRmCn1O0/+h/VBf2bpPd\n7auIfWcyIjm7j/77C72qdhftma6tozrYvifs6+YRjv268snYTfTqJkJmobJNV73Uh721suLUuzc2\nWlmVZ+3XaN92Dhm9uw7dPps5oaoz81931oBx6r7PTmSXjaeiR+RwkTnx9sDa9coRsnbOrksmp6qD\nbzPFYxy7n0y/eBmrqAVZoFUEgkYzkX7V6GFlFIwObFSK9p3Jy9rudMrmAzkodpEP4ow67CJT1L4Y\n59Ht/37OtmUyQ+vcGR2ivjNdqkRy2IDQytvhs67OWnqO1tijBb5hHDJqZJEMJsX0z2TGu9PBR+2f\ncigZ0RpUoznfbyV9rsjJ9EJ1uOezM6eTGw9Nt60DYJ1YtfRR0WVSzm1ju33oyeZwZ3tetrUNq9Oq\nv0gmGgSs+upy/Ien3UH59qvJj4gWk4nSrNOw2QbrSLolF9RxRP1nuu/GlEVQjBOyhxwzl955VPuN\nXk9Ehd3ojMlcMtD1iLJhdjzRPFacs2/j31+NKct47L9Ke6+Hty32sGX2ScbXHfvK4bAb2E/sqjwT\ntV2VMFg92HHcdA4Eb6hVWVUjQyJMvy5Iun33X93wNyunUykVrF53ov4pJ+wDkZ0+/vusbVt5zFi8\nfVkbQ+Z1ZUds+aSzpn5t2AzXl4I6Dv7rNfZVmsTUtiIZq35WOu363p3mdoEq8la62D5RZ+jbIhvG\ny0FLSpk8pjyWOa7dnOyyjanSA9N+F6lWZESZoSfLRP330PnoOMPu/r6Jsge2vR8P4ze8Hh0b986d\n5XgppmNkXo79H2lzE01mt6SBONVIH0SG7xM1jlXk1I020bGsopaqI8w2HpPB+NeddLtjU5Ez381R\nZler9lnfd3vG6exKKBWZ3ukxc7nLyhAqh2xVp0m9jv1WTLRJmBM9O30rZMbPnLzR11YndEwVPaJD\nsWvwrPPybVYHVVVOdtAi5RirE6rH6qBnHLKXy9iEfb2KxC2+v+58dJyX7x91hj6iZQ6ZqP0ng7aM\nTPduRnNdByP2e0H9wnbS5NVE7xahc1pmY2DKQojRZ/Nm+2UM37fpzkXVEduvow2HOIHM2TFr4W21\n69gyPVbrZPvOnlsFANHX6FgmnFB0wKF0yie2/e7Aq8ixsGOJZHV5zO+xdwe2a58ZURT5RN9DdWBT\n7C7RWJgxdKMzK6sip3owsmvCjGNqs1XnoeroOsFPxy47crJ2p+RMjWlqz07t/5vjNfbTVCPik3pM\n0IkmulQiya6sv8Bf1B3NtgTHtG38aFGEEOJd/OcjdiGEeBty7EII8TLk2IUQ4mXIsQshxMuQYxdC\niJchxy6EEC9Djl0IIV7GVz95+vOQv/L9aRm7T5H9bv6K/O4OC0SHjowdU3OB6BHd1fJN21iNh9HD\ny5sai21P3Evz5+aza+er/XLLuK7rN7sKYvfp0cn5qPCoiL3zYSl/OxwrK7pE65vtO0zcw5G18fOL\nypyYz9vomftN7vb2H6OLv6eEwepQHUtk29Vx+CsZoq9Rpuz7ns+qPP+cPei7Ou0uFcvWyrep6LHr\nozuWR9wVM+0EO7e1de9tiDZ+VWZ0ERbat5eD4u81iSJkRmbnkNltuEp7rwt7eVXn8qmpdfHvoXLY\nNfX3xnRsw7Zl72OaCuSm7q9B2gdZwT++19XhURE7Q3TadyaFdSJ327t/+6+rE6sD2693XqwM5KCs\nRDBodJtd8NS97Gli40UyojnInFc3A0IjZd9mItpn5zDqm1mTCb9h5+IbB0KV447dOo+TlyRNOMQp\nJvueiBKtnJU8NIWtPMNsmsgJd7Iwf2BPHPqZc8re69pnVMrqZKUTe5YtaXXLLtW5n5Rfeb5jo57j\njv265up+ExGFb9tN/xlduqWkLpFDrzjHVVTMrkl3PN4hIs4ks4NuxM/KuPXozG1ml1P7pUpn/Fkw\nWNUj6tuOA81ivB7IwePXk9XDc9Sxr9JMdHK9jA72gJg6QdnxnHSGE2UpP4+oQ70urmzgN4h/jWQR\nNspmD+rowLf/o/KsXDZyRstTke6MY7Vt0XnwGU90QFVtzJf50MzO2oP/V8X3+YqIfdJpRkbKOJHo\nPTbiRg3dfs0edNa4Jg881OCvK4/8d/i581lDlczhMWvTcWKRvPv/nS7RIWfbVnWxjiNzplU9Mhmd\nGjca5a5gbaxz2HZ8WTSf3aDyeMRuU5nqYLIFiFKiHXZSo1MT1Slr1114tjSD9s1uNkvkfCL5FTnM\nGGxbP56O82GcWMfx2TbZHumMx7ffldkm1jWaj90YVocb2j/67KdlWhtlS0sRx2vsUXS6W+jMAUcO\nH4lmOid2BOuUMjm7Z7KNgqSn0euO/oxjjSJZNMXN5EbRNyurQmWjVuckiuqYwKNz2HbaWKIoNQsk\nkLVCSmwdGbt2iJ3fz0eBCMtjSjGrSCLDRvyZbMTo/cIgEV72XHUTrdpn38uMYJfJZETP2SgRjbZZ\ndpHjN3SwMlb21ZXN6tGxT2avIbpV9GAPuVWwMbEmto8d2d5+wpoc/4DSlAPopKeTJZPKM53IrfL8\nxEaNXk/p9632UzK6cqZ0eIIep2VEe5XNwE6PZVKG53gpRszyCSMR4snI5v/Nqx37J35IIv7NW+f5\nreP6JprDM/xo4oUQ4l28OmIXQoj/InLsQgjxMuTYhRDiZcixCyHEy5BjF0KIlyHHLoQQL0OOXQgh\nXoYcuxBCvIyv3hXz8/NDfxrq9/f3500ynqCDZLxXxhN0eLoM4GZMSI/kWuOxsVRQxC7El9GnvZ/B\np+6YecLdNY9x7Oh92+wl+wgTd4Cf7HtC94k/IIDK2T2L6tSdS38XOnJvf3a/+Mn5mOAb+w/Vo9uW\nsaspnaI2Hbs9fm1vNLnVE88+27mg/5MOEDm9s8Wtytm1Z/4ow/0auR8/2/TVsezu7K6y27iVOdmN\nhdXFvs/0b+e5Y+fVOYjWxH9duUu9ex+7lxfJqt7pbr9GrwBGDvesvZ+Ljg/zHIvYVwtbmaz7cv/M\nuKf+MATrUO33qpFddNc02v/qDxBksnw0mt15vRvLag4R5+P7if7IRJXdH8qoOtWoHeKQo2crTmSn\n+8rOoyzDy0R0WO1Z5G8R3H12ShaZM6/qET37zb83YOfCy5oo5RyL2LPJRU/A6KRlT9FV+93mTH5g\nAvcdyahuvEhG9ZD07fyhiWRSfk12B0/U1uvPrGl3g0S6WH1W8u2cRpt30jZ2QUmkA7qmXqbVAYnW\no0NlSg+Urs/oZlDZwTJRQXhMjf26sLKDJ3LwzARnTigzpEpfzHi8U51kVbKJvu5sGsSpR7qtDi1E\nzqptdXydrAF53zOx/tkBUJUdlbWYw2mVOVTxByx76GfZEDquiUPmbmf3fScwOe7Yo4gMMbYozayU\nDdC+PLs0vLu4E6mZn9vVwRkdjEx/Xn+/eRlHwthGFhlGcqoOn9EDfTZilTkw/WclAEQH1vGsnCCy\nthPlipX8lT5+j0Q2z9h5lNGwHP/h6S5lrbS9Qdt3nNhKpmXCKaMy2PrjapMhtctV+QQtK91fT2Rz\nVhYynkiP66qvTbRZkXFEm5+Lx8p0AAAKVklEQVSJlr0slF3UjRBlpN1MvaOH1WW3Xyaz9FXW8Kcj\n9uviIogMxOhX0QOrx4T+0f9VOgeLjRjs/936Z/T+NyNeK4MtK0WZIeqc2c1699UppdzPTgQyVpdu\nxnvrxJTpfIbI7JUos2OZaD/lB49H7Nc1c0LddOVMRvDoxp/adLe8Dlafjm7Z2jIbeWp+0LmZmFNb\nIpyIcu3/qIzOfpsIfrycKmhgsHtmotyZyUOZrh4cj9itsbPR1Cd0YtuxqfbUodaJYCwdo/dpdscB\nsTpk+jCymANmZUMTdt6J/Cfsjd2vkT4ovlxSyRAjGf71RDDEtLHZ5JQ/O+7Yr6sXgUzV2LqRjNVl\npU9Wd44WtbN5u0TlB0SH6Gukb9++s75MXdq3t7qwrEoqaFt2bTqOY+Kw9T+j6DqziVJQBxs0dPfr\n1N69rgeUYqYG0nXG9v8p5559f/dDxVP1/U/JQuczKtt0N3Akl9WFaTfNiXLjxAH3FBleVmajSDmH\nZboMc13X9fOJUoYQQohzPKIUI4QQYg45diGEeBly7EII8TLk2IUQ4mXIsQshxMuQYxdCiJchxy6E\nEC/jqx9Q+nnwXyz/town6MDIcHfIPGY+/8sygsusUvuqfBjmL8/FW2RE63TLqPCIiH3yjgQrs9vu\n9Ie3vtF/1Ie/u2Lq4qcn8KQ1ndIFubvmE+t3ek7fwqtud4wMffWxfuSjv+hHdSNdEBnRXS/VhXKR\ncPp+RU5ENqdBVADNe1UPZC58n94uMt2runjZ1bXx+q/aJhHXP/5HN68fOyJndY9RRw+WzD6qh9Tq\nmomdrGyv2fYIq/lADt1MP8bJH43YGQNbOXXmrodIhr04qsoq8q0QGZq/8Il16l5ehexyIzS78u3Z\nTcM69ZXMlRzvhP1mY+d64qIn9j6jTzhkqw8qw9sVcg/Pyql72dkz2fvMWKK+2XuF7vF17pA56tit\nke82WMbucGBOzGrfGfe4VlFSpX3mXBEZnqpDsjpYA6voEkUgHSIbQQ/su320NkyfE06VGcP9muk/\nc4iduWT16QRQ3YzDt43GUZ2TSP+O35jiETX268rLD9UN6OWgBuMXlIn0O7p4g2WMwxtp9kxFD1Yf\npFSGyLH67OZzdVBHY0NgnVl0QExFdJ0MAmEi2/AZkNWdHUe3tBWVPqqyvP4rPVcyouwFzYQsj3Hs\n19X/wVKWtu+opHartnffkf5VXTKnzJZP7tdoNJEZNeqEullHJ1KulH6QjRutTceJsESbHdGHtXEv\nw+vAROten2omtXq2M7ed0lb3sFsdzn+yFJPRjQyQRVrVsiYcUVXORP2zEr2x88oetGhqm7VnmSgD\n+TntjMnLQFht/mrw0O3f/1/NGFb9TtlkZ0z31+ie98ELq8c0x394Gp3ayIaZ2LidlCeTVymLeDID\nQbMP2x495O7/o/SfpXNQT6xv5b1V/1EWMnHo2D5Y0DXOyjpdvu3MIqfeKa+xfiDas6j/6sqIeFTE\nzqQ2mdOoRhGr2m3ngKn0v6oFR5EAo8fufYvtMytBIEwemLc8hK4DjiLUyZQdLaN4+0QixFt3H0ix\nh8Kq3IfKQiL++/lMJzSIyvSq+g5/2DNRv/9/Img49nvsWa0OHdSk42Br9LaNj/Ds/1GbnS5Vdill\nN+JmdWEOqGgOI7kVGajTsPhNzpQyVnowMqL3K0SOFM2kov3RsY1ItwrWTzBBkG8T2VVFTuS/UKKy\nln2f3bfHIvYsymYW2b9mal2TKXt3HEzWkGUbrGF0U1uvR6c9k6pGzzAlIX9gTswJeuBk42VKbNHh\ngNKxrawUxETsq9JhVUakEyIjy8KqRDZtS0Msxz95Wj1hURlsesmm28xhstOlK+OTOjBr0tHFv1eN\nqG6668qyms9u4IG2jTLijg4TZRhUh0wPRE43iLNtoqCDkdPRI+JRNfaMqcFW+/pmf3+VvzZH3XWd\nLPld19+bv4gnjGGiHt1h0l9MjuNn2mCFEEKc5U9E7EIIIerIsQshxMuQYxdCiJchxy6EEC9Djl0I\nIV6GHLsQQrwMOXYhhHgZX/3k6c8f+0vhn5TxBB0k470yvq2D/6DQk+bibTIqKGIXEFMfaHv6B+Oe\nrt/TeMKnUMX/8RjH7q8V7VxOtGubfd/q0NWj6xjY9r7vCTmTN9gxcrrzycxJpt/Euk6P55QMtl//\nNaMLeplZ9P2JvR7JQ/TyekzYx3U94BKw6/r3daDoTYn++V079Fa8KtGidm8TvC5O346cSGZHF3tZ\nEjIn2Sbptq/oEdnU3Td6QFWcTmeN0bb+cjT0kM2oXsyWjaGjy679bsyMfUZ6+D6YObHvsZnQ8b+g\ndF3/vkgnujUta59tsmiydrrYG9rYxWVvebMHWvemyFsGc2ucn8+ujEgmIyPSByGaE1QP9lbCzK66\nBxVCduizNysycxH1e88Jc7it9snuAPK+hw16JhxyJ/DKeEQpxkeF1YmpRly7vic2r33WR6hIW9uG\nkRHJQZlKTW+doq8r8v2mQ1LU7Dl0PTKdmY2bOQG0LeqIdo58uiSTyYucXndNbZbv39/RdaTZXCKH\nXBbZd6L16zpciokURyNtC1MKscbGGMeqf6Yts/l3/Xciwu6mX5U/orFlJRDbJpO3eo6NUrNIl2kf\nyavap/0a1WN1MKKOaLU2kc6RDNamsjLOhCz7vpW/Cx5Xsnb9R7KmOBax30bGRqeWzClP1Q4rbSsO\nhu2byRoQ+bZtZxwV+ZVnqk54J8/a1/RGWjlsS0f/qM9ORtkBOWxXMjL90bJWBhoE+f6rtrcLQKo6\nIPaOcLQU06nXRTLYMkRUZ2OdKSPD9h3NCTKWKCpG6R6KbM3St++Ow8pi5yWzL8Rmo/Eg+HJUJ5P0\ntobaeTQHiGPypQcmAv9EAIKW2Pw8MPvV2qVfX+vwmYPj+N88jQaH4qN/K59lInNg0jNfe7vfr7aP\nnp1wsrtIDNGH0YFdDy+DPeiuaz7KZ/RgbCyLSjslkbs9czhkeqFr0w0Iu/3bNnYu2Pnwrzt6PeKH\np9f1z7S5W69iHYGV1YmKMr1QPaZ+1tABjWR8O7b9JB3b8kwcVlPtWV26GYTVgan5d9pNM2Gf1bLc\nTkZnz3se8XvsPo2ZivKqRH2ienRO153Mb7fNfljXiUS6unToROtezq3TKefedUQTuk8d1lM22sXb\nO3tYdnSK2nTW6njEHtVnWToRjC+BMHKikhCjS9fg0ZPfp/ZRLRU9KDNZKDa6PFFey3RiZHbLjZX3\npmSveFLW0v0tmU5ANvmzpWgcnTk6HrFPRXaT6e0pHSZgxhHV9bLXn9Lh03xKl2+NMZrTbmQ4cfCe\nZMJWfbtTWfr0nvl5Qp1LCCHEHMdLMUIIIWaRYxdCiJchxy6EEC9Djl0IIV6GHLsQQrwMOXYhhHgZ\ncuxCCPEy5NiFEOJlyLELIcTLkGMXQoiXIccuhBAvQ45dCCFehhy7EEK8DDl2IYR4GXLsQgjxMuTY\nhRDiZcixCyHEy5BjF0KIlyHHLoQQL0OOXQghXoYcuxBCvAw5diGEeBly7EII8TL+P1KfdeMv+xOV\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f08e20630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P10(num_examples):\n",
    "    BernoulliNB_digits = BernoulliNB(binarize=0.0)\n",
    "    BernoulliNB_digits.fit(mini_train_data,mini_train_labels)\n",
    "### STUDENT START ###\n",
    "    counter = 1\n",
    "    for i in range(0,10):\n",
    "        for j in range(0,num_examples):\n",
    "            Probs = np.exp(BernoulliNB_digits.feature_log_prob_[i,:])\n",
    "            RandPixels = np.random.rand(784)\n",
    "            BinaryRandPixels = (RandPixels >= Probs)\n",
    "            plt.subplot(10,num_examples,counter)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(BinaryRandPixels.reshape([28,28]),cmap='Greys')\n",
    "            counter += 1\n",
    "### STUDENT END ###\n",
    "\n",
    "P10(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The images are not bad - the \"lines\" of the digit are less discrete and there are gaps in the middle where even high probability pixels occasionally end up blank. That being said, these examples can generally be interpreted to the digit of origin by the human eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Remember that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior and accuracy.\n",
    "\n",
    "Train a BernoulliNB model with a reasonable alpha value. For each posterior bucket (think of a bin in a histogram), you want to estimate the classifier's accuracy. So for each prediction, find the bucket the maximum posterior belongs to and update the \"correct\" and \"total\" counters.\n",
    "\n",
    "How would you characterize the calibration for the Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BernoulliNB_digits = BernoulliNB(binarize=0.0,alpha=0.1)\n",
    "BernoulliNB_digits.fit(mini_train_data,mini_train_labels)\n",
    "\n",
    "predictions = BernoulliNB_digits.predict(dev_data)\n",
    "confidences = BernoulliNB_digits.predict_proba(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(pred) <= 0.5000000000000    total =   2    accuracy = 0.000\n",
      "p(pred) <= 0.9000000000000    total =  31    accuracy = 0.387\n",
      "p(pred) <= 0.9990000000000    total =  71    accuracy = 0.493\n",
      "p(pred) <= 0.9999900000000    total =  53    accuracy = 0.434\n",
      "p(pred) <= 0.9999999000000    total =  64    accuracy = 0.609\n",
      "p(pred) <= 0.9999999990000    total =  46    accuracy = 0.543\n",
      "p(pred) <= 0.9999999999900    total =  52    accuracy = 0.808\n",
      "p(pred) <= 0.9999999999999    total =  49    accuracy = 0.796\n",
      "p(pred) <= 1.0000000000000    total = 632    accuracy = 0.951\n"
     ]
    }
   ],
   "source": [
    "def P11(buckets, correct, total):  \n",
    "### STUDENT START ###\n",
    "    BernoulliNB_digits = BernoulliNB(binarize=0.0,alpha=0.1)\n",
    "    BernoulliNB_digits.fit(mini_train_data,mini_train_labels)\n",
    "\n",
    "    predictions = BernoulliNB_digits.predict(dev_data)\n",
    "    predictionsDF = pd.concat([pd.Series(dev_labels,name='Actual'),pd.Series(BernoulliNB_digits.predict(dev_data),name='predictions')],axis=1)\n",
    "    predictionsDF['Correct'] = (predictionsDF.Actual == predictionsDF.predictions)\n",
    "\n",
    "    confidences = BernoulliNB_digits.predict_proba(dev_data)\n",
    "    #artificially setting limit on confidences to 0.5, since thats our minimum bucket.\n",
    "    ConfBuckets = np.digitize(right=True,x=np.amax(confidences,axis=1), bins=[0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0])\n",
    "    Aggregate = pd.concat([predictionsDF.Correct,pd.Series(np.amax(confidences,axis=1),name='MaxConf'),pd.Series(ConfBuckets,name='ConfBucket')],axis=1)\n",
    "\n",
    "    Aggregate = pd.concat([Aggregate.groupby('ConfBucket')['Correct'].agg(['sum','count']), pd.Series(buckets,name='ConfidenceBin')],axis=1).reset_index()\n",
    "    Aggregate.drop('ConfBucket',inplace=True,axis=1)\n",
    "    Aggregate.set_index('ConfidenceBin')\n",
    "    Aggregate['Accuracy'] = Aggregate['sum'] / Aggregate['count']\n",
    "    \n",
    "    return Aggregate\n",
    "### STUDENT END ###\n",
    "\n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "Aggregate = P11(buckets, correct, total)\n",
    "correct = np.asarray(Aggregate['sum'])\n",
    "total = np.asarray(Aggregate['count'])\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "    accuracy = 0.0\n",
    "    if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "        \n",
    "    print('p(pred) <= %.13f    total = %3d    accuracy = %.3f' % (buckets[i], total[i], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: It appears that the calibration for our Naive Bayes model is reasonably good. We see a positive correlation between the posterior probability and the accuracy of the bin. That being said, the accuracy values are not a 1:1 mapping with the confidence itself (e.g. 90% posterior does not correlate to a 90% accuracy).\n",
    "\n",
    "PS: My approach to this problem didn't follow the instructions in entirety: rather than iterate through the predictions, I used np.digitize to bucketize all confidences at once. The group by command then let me summarize correct and incorrect by those buckets. I return a dataframe that has bucket, count, correct, and accuracy attributes and reproduce the \"correct\" and \"total\" vectors for the text printing from that. Apologies for any inconvenience: but the vectorized approach seemed more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) EXTRA CREDIT\n",
    "\n",
    "Try designing extra features to see if you can improve the performance of Naive Bayes on the dev set. Here are a few ideas to get you started:\n",
    "- Try summing the pixel values in each row and each column.\n",
    "- Try counting the number of enclosed regions; 8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0.\n",
    "\n",
    "Make sure you comment your code well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def P12():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P12()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
