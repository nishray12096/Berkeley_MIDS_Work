{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll work with text data from newsgroup postings on a variety of topics. You'll train classifiers to distinguish between the topics based on the text of the posts. Whereas with digit classification, the input is relatively dense: a 28x28 matrix of pixels, many of which are non-zero, here we'll represent each document with a \"bag-of-words\" model. As you'll see, this makes the feature representation quite sparse -- only a few words of the total vocabulary are active in any given document. The bag-of-words assumption here is that the label depends only on the words; their order is not important.\n",
    "\n",
    "The SK-learn documentation on feature extraction will prove useful:\n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but please prepare your own write-up and write your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, stripping out metadata so that we learn classifiers that only use textual features. By default, newsgroups data is split into train and test sets. We further split the test so we have a dev set. Note that we specify 4 categories to use for this project. If you remove the categories argument from the fetch function, you'll get all 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2034L,)\n",
      "test label shape: (677L,)\n",
      "dev label shape: (676L,)\n",
      "labels names: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "num_test = len(newsgroups_test.target)\n",
    "test_data, test_labels = newsgroups_test.data[num_test/2:], newsgroups_test.target[num_test/2:]\n",
    "dev_data, dev_labels = newsgroups_test.data[:num_test/2], newsgroups_test.target[:num_test/2]\n",
    "train_data, train_labels = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "print 'training label shape:', train_labels.shape\n",
    "print 'test label shape:', test_labels.shape\n",
    "print 'dev label shape:', dev_labels.shape\n",
    "print 'labels names:', newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) For each of the first 5 training examples, print the text of the message along with the label.\n",
    "\n",
    "[2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_lookup = pd.DataFrame(newsgroups_train.target_names).reset_index()\n",
    "label_lookup.columns = ['LabelNum','LabelName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  LabelNum  \\\n",
      "0  Hi,\\n\\nI've noticed that if you only save a mo...         1   \n",
      "1  \\nAcorn Replay running on a 25MHz ARM 3 proces...         1   \n",
      "2  I'm interested in find out what is involved in...         1   \n",
      "3  \\n\\nSeems to be, barring evidence to the contr...         3   \n",
      "4  \\n >In article <1993Apr19.020359.26996@sq.sq.c...         2   \n",
      "5  AW&ST  had a brief blurb on a Manned Lunar Exp...         2   \n",
      "6  Mark Prado\\n  \\n  \\nOld pioneer song from the ...         2   \n",
      "7  \\nTheir Hiten engineering-test mission spent a...         2   \n",
      "8  I have a request for those who would like to s...         0   \n",
      "9  \\nThere are definitely quite a few horrible de...         0   \n",
      "\n",
      "            LabelName  \n",
      "0       comp.graphics  \n",
      "1       comp.graphics  \n",
      "2       comp.graphics  \n",
      "3  talk.religion.misc  \n",
      "4           sci.space  \n",
      "5           sci.space  \n",
      "6           sci.space  \n",
      "7           sci.space  \n",
      "8         alt.atheism  \n",
      "9         alt.atheism  \n"
     ]
    }
   ],
   "source": [
    "def P1(num_examples=5):\n",
    "### STUDENT START ###\n",
    "#Join to add labels\n",
    "    FiveExamples = pd.concat([pd.DataFrame(train_data).head(num_examples),pd.DataFrame(train_labels).head(num_examples)],axis=1)\n",
    "    FiveExamples.columns = ['Message','LabelNum']\n",
    "    result = FiveExamples.merge(label_lookup, on='LabelNum', how='inner')\n",
    "    print result\n",
    "### STUDENT END ###\n",
    "P1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Use CountVectorizer to turn the raw training text into feature vectors. You should use the fit_transform function, which makes 2 passes through the data: first it computes the vocabulary (\"fit\"), second it converts the raw text into feature vectors using the vocabulary (\"transform\").\n",
    "\n",
    "The vectorizer has a lot of options. To get familiar with some of them, write code to answer these questions:\n",
    "\n",
    "a. The output of the transform (also of fit_transform) is a sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html. What is the size of the vocabulary? What is the average number of non-zero features per example? What fraction of the entries in the matrix are non-zero? Hint: use \"nnz\" and \"shape\" attributes.\n",
    "\n",
    "b. What are the 0th and last feature strings (in alphabetical order)? Hint: use the vectorizer's get_feature_names function.\n",
    "\n",
    "c. Specify your own vocabulary with 4 words: [\"atheism\", \"graphics\", \"space\", \"religion\"]. Confirm the training vectors are appropriately shaped. Now what's the average number of non-zero features per example?\n",
    "\n",
    "d. Instead of extracting unigram word features, use \"analyzer\" and \"ngram_range\" to extract bigram and trigram character features. What size vocabulary does this yield?\n",
    "\n",
    "e. Use the \"min_df\" argument to prune words that appear in fewer than 10 documents. What size vocabulary does this yield?\n",
    "\n",
    "f. Using the standard CountVectorizer, what fraction of the words in the dev data are missing from the vocabulary? Hint: build a vocabulary for both train and dev and look at the size of the difference.\n",
    "\n",
    "[6 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.\n",
      "Vocabulary size: 26879\n",
      "Non-zero features per sample: 96.706\n",
      "Percentage of nonzero elements: 0.3598%\n",
      "b.\n",
      "word zero: 00\n",
      "last word: zyxel\n",
      "c.\n",
      "Shape of truncated count vectorizer: (2034, 4)\n",
      "Non-zero features per sample: 0.2684\n",
      "d.\n",
      "Vocabulary of bigrams and trigrams: 28954\n",
      "e.\n",
      "Vocabulary of words with >10 occurrences: 3064\n",
      "f.\n",
      "Percentage of dev vocab not in training vocab: 0.9024\n"
     ]
    }
   ],
   "source": [
    "def P2():\n",
    "### STUDENT START ###\n",
    "    cv = CountVectorizer()\n",
    "    train_CV = cv.fit_transform(train_data)\n",
    "    #a. use vectorizer properties\n",
    "    print \"a.\"\n",
    "    print \"Vocabulary size: \" + str(train_CV.shape[1])\n",
    "    print \"Non-zero features per sample: \" + str(round(float(train_CV.nnz) / (train_CV.shape[0]),4))\n",
    "    print \"Percentage of nonzero elements: \" + str(round(float(train_CV.nnz) * 100 / (train_CV.shape[0] * train_CV.shape[1]),4)) + \"%\"\n",
    "    \n",
    "    #b.\n",
    "    print \"b.\"\n",
    "    print \"word zero: \" + cv.get_feature_names()[0]\n",
    "    print \"last word: \" + cv.get_feature_names()[len(cv.get_feature_names())-1]\n",
    "    \n",
    "    #c.\n",
    "    print \"c.\"\n",
    "    truncVocab = [\"atheism\", \"graphics\", \"space\", \"religion\"]\n",
    "    trunc_CV = CountVectorizer(vocabulary = truncVocab)\n",
    "    trunc_Data_CV = trunc_CV.fit_transform(train_data)\n",
    "    print \"Shape of truncated count vectorizer: \" + str(trunc_Data_CV.shape)\n",
    "    print \"Non-zero features per sample: \" + str(round(float(trunc_Data_CV.nnz) / (trunc_Data_CV.shape[0]),4))\n",
    "    \n",
    "    #d.\n",
    "    print \"d.\"\n",
    "    ngram_CV = CountVectorizer(ngram_range=(2,3),analyzer='char_wb')\n",
    "    ngram_CV_Data = ngram_CV.fit_transform(train_data)\n",
    "    print \"Vocabulary of bigrams and trigrams: \" + str(ngram_CV_Data.shape[1])\n",
    "    \n",
    "    #e.\n",
    "    print \"e.\"\n",
    "    cv_min = CountVectorizer(min_df=10)\n",
    "    train_CV_min = cv_min.fit_transform(train_data)\n",
    "    print \"Vocabulary of words with >10 occurrences: \" + str(train_CV_min.shape[1])\n",
    "    \n",
    "    #f.\n",
    "    print \"f.\"\n",
    "    cv = CountVectorizer()\n",
    "    train_CV = cv.fit_transform(train_data)\n",
    "    cv_dev = CountVectorizer()\n",
    "    cv_dev_data = cv_dev.fit_transform(dev_data)\n",
    "    dev = cv.get_feature_names()\n",
    "    trainVocab = cv_dev.get_feature_names()\n",
    "    \n",
    "    missingCounter = 0\n",
    "    for word in dev:\n",
    "        if word not in trainVocab:\n",
    "            missingCounter += 1\n",
    "            \n",
    "    print \"Percentage of dev vocab not in training vocab: \" + str(round(float(missingCounter) / cv_dev_data.shape[1],4))\n",
    "### STUDENT END ###\n",
    "P2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Use the default CountVectorizer options and report the f1 score (use metrics.f1_score) for a k nearest neighbors classifier; find the optimal value for k. Also fit a Multinomial Naive Bayes model and find the optimal value for alpha. Finally, fit a logistic regression model and find the optimal value for the regularization strength C using l2 regularization. A few questions:\n",
    "\n",
    "a. Why doesn't nearest neighbors work well for this problem?\n",
    "\n",
    "b. Any ideas why logistic regression doesn't work as well as Naive Bayes?\n",
    "\n",
    "c. Logistic regression estimates a weight vector for each class, which you can access with the coef\\_ attribute. Output the sum of the squared weight values for each class for each setting of the C parameter. Briefly explain the relationship between the sum and the value of C.\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               parameters  mean_validation_score\n",
      "0     {u'n_neighbors': 1}               0.409046\n",
      "1     {u'n_neighbors': 5}               0.409046\n",
      "2    {u'n_neighbors': 10}               0.413471\n",
      "3    {u'n_neighbors': 20}               0.418879\n",
      "4    {u'n_neighbors': 30}               0.404621\n",
      "5    {u'n_neighbors': 40}               0.412488\n",
      "6    {u'n_neighbors': 50}               0.432153\n",
      "7    {u'n_neighbors': 75}               0.425270\n",
      "8   {u'n_neighbors': 100}               0.434612\n",
      "9   {u'n_neighbors': 125}               0.438053\n",
      "10  {u'n_neighbors': 150}               0.445919\n",
      "11  {u'n_neighbors': 175}               0.442970\n",
      "Best KNN neighbors parameter: \n",
      "{'n_neighbors': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           parameters  mean_validation_score\n",
      "0     {u'alpha': 0.0}               0.811701\n",
      "1  {u'alpha': 0.0001}               0.825467\n",
      "2   {u'alpha': 0.001}               0.825959\n",
      "3    {u'alpha': 0.01}               0.828417\n",
      "4     {u'alpha': 0.1}               0.822026\n",
      "5     {u'alpha': 0.5}               0.808751\n",
      "6     {u'alpha': 1.0}               0.795969\n",
      "7     {u'alpha': 2.0}               0.773845\n",
      "8    {u'alpha': 10.0}               0.684366\n",
      "Best Multinomial NB alpha parameter: \n",
      "{'alpha': 0.01}\n",
      "    parameters  mean_validation_score\n",
      "0    {u'C': 1}               0.763029\n",
      "1    {u'C': 2}               0.762537\n",
      "2    {u'C': 3}               0.762537\n",
      "3    {u'C': 4}               0.761554\n",
      "4    {u'C': 5}               0.759587\n",
      "5    {u'C': 6}               0.758112\n",
      "6    {u'C': 7}               0.757620\n",
      "7    {u'C': 8}               0.754671\n",
      "8    {u'C': 9}               0.754179\n",
      "9   {u'C': 10}               0.754671\n",
      "10  {u'C': 11}               0.753196\n",
      "11  {u'C': 12}               0.753196\n",
      "12  {u'C': 13}               0.754179\n",
      "13  {u'C': 14}               0.754671\n",
      "                    parameters  mean_validation_score\n",
      "0                  {u'C': 0.1}               0.766470\n",
      "1                  {u'C': 0.2}               0.776303\n",
      "2  {u'C': 0.30000000000000004}               0.770895\n",
      "3                  {u'C': 0.4}               0.772861\n",
      "4                  {u'C': 0.5}               0.771386\n",
      "5                  {u'C': 0.6}               0.770895\n",
      "6   {u'C': 0.7000000000000001}               0.768928\n",
      "7                  {u'C': 0.8}               0.768437\n",
      "8                  {u'C': 0.9}               0.764503\n",
      "Best LR C parameter: \n",
      "{'C': 0.2}\n",
      "C value versus total coefficient squared (part c): \n",
      "    coefs         0.1         0.2  0.30000000000000004         0.4  \\\n",
      "0.1   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.2   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.3   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.4   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.5   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.6   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.7   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.8   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "0.9   NaN  102.269555  184.474515           254.829172  317.234669   \n",
      "\n",
      "            0.5         0.6  0.7000000000000001         0.8         0.9  \n",
      "0.1  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.2  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.3  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.4  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.5  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.6  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.7  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.8  373.763513  425.625969          473.733803  518.961385  561.608138  \n",
      "0.9  373.763513  425.625969          473.733803  518.961385  561.608138  \n"
     ]
    }
   ],
   "source": [
    "def P3():\n",
    "### STUDENT START ###\n",
    "    cv = CountVectorizer()\n",
    "    train_CV = cv.fit_transform(train_data)\n",
    "    \n",
    "    #Using GridSearchCV to find best parameters in each case\n",
    "    \n",
    "    KNN_Model = KNeighborsClassifier()\n",
    "    KNNGridSearch = GridSearchCV(KNN_Model,param_grid={'n_neighbors': [1, 5, 10, 20, 30, 40, 50, 75, 100, 125, 150, 175]})\n",
    "    KNNGridSearch.fit(train_CV,train_labels)\n",
    "    print pd.DataFrame(KNNGridSearch.grid_scores_)[['parameters', 'mean_validation_score']]\n",
    "    #shows that the best score could be more than 100 - score still climbing\n",
    "    print \"Best KNN neighbors parameter: \"\n",
    "    print(KNNGridSearch.best_params_)\n",
    "    KNN_Model = KNeighborsClassifier(n_neighbors = KNNGridSearch.best_params_['n_neighbors'])\n",
    "    KNN_Model.fit(train_CV,train_labels)\n",
    "    \n",
    "    MultiNB = MultinomialNB()\n",
    "    MultiNBSearch = GridSearchCV(MultiNB,param_grid={'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]})\n",
    "    MultiNBSearch.fit(train_CV,train_labels)\n",
    "    print pd.DataFrame(MultiNBSearch.grid_scores_)[['parameters', 'mean_validation_score']]\n",
    "    print \"Best Multinomial NB alpha parameter: \"\n",
    "    print(MultiNBSearch.best_params_)\n",
    "    MultiNB = MultinomialNB(alpha=MultiNBSearch.best_params_['alpha'])\n",
    "    MultiNB.fit(train_CV,train_labels)\n",
    "    \n",
    "    LR = LogisticRegression(penalty='l2',C=1)\n",
    "    LRSearch = GridSearchCV(LR,param_grid={'C': np.arange(1,15)})\n",
    "    LRSearch.fit(train_CV,train_labels)\n",
    "    print pd.DataFrame(LRSearch.grid_scores_)[['parameters', 'mean_validation_score']]\n",
    "    #shows that the best score could be less than one - score only drops from 1 onwards\n",
    "    #will retry the grid search\n",
    "    LR = LogisticRegression(penalty='l2',C=.1)\n",
    "    LRSearch = GridSearchCV(LR,param_grid={'C': np.arange(.1,1,step=.1)})\n",
    "    LRSearch.fit(train_CV,train_labels)\n",
    "    print pd.DataFrame(LRSearch.grid_scores_)[['parameters', 'mean_validation_score']]\n",
    "    print \"Best LR C parameter: \"\n",
    "    print(LRSearch.best_params_)\n",
    "    \n",
    "    LR = LogisticRegression(penalty='l2',C=LRSearch.best_params_['C'])\n",
    "    LR.fit(train_CV,train_labels)\n",
    "    \n",
    "    WeightsDF = pd.DataFrame(columns = ['coefs'], index = np.arange(.1,1,step=.1))\n",
    "    \n",
    "    for C in np.arange(.1,1,step=.1):\n",
    "        LR = LogisticRegression(penalty='l2',C=C)\n",
    "        LR.fit(train_CV,train_labels)\n",
    "        WeightsDF[C] = np.sum(np.square(LR.coef_))\n",
    "    print \"C value versus total coefficient squared (part c): \"\n",
    "    print WeightsDF\n",
    "### STUDENT END ###\n",
    "P3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWERS:\n",
    "a. Nearest neighbors is calculating a vector distance between each training datapoint. Using a simple count vectorizer, simple, uninformative words will confound these vector distances (words like: the, and, it, or).\n",
    "\n",
    "b. Naive Bayes allows for weighting of words by likelihood of occurrence overall. Logistic regression can only add a linear probably to a cumulative sum based on the presence of a given word. This could be limiting the impact of \"rare\" words, while Naive Bayes takes full advantage of rare but high information words.\n",
    "\n",
    "c. In L2 regularization, the magnitude of the coefficients is penalized. When we increase C, we increase the degree to which coefficient magnitude is penalized, and thus the coefficients on each individual word will be dampened to compensate for the increased penalty terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Train a logistic regression model. Find the 5 features with the largest weights for each label -- 20 features in total. Create a table with 20 rows and 4 columns that shows the weight for each of these features for each of the labels. Create the table again with bigram features. Any surprising features in this table?\n",
    "\n",
    "[5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram most important words and weights\n",
      "       alt.atheism  comp.graphics  sci.space  talk.religion.misc       words\n",
      "22567    -0.819150      -0.875358   1.505895           -0.740853       space\n",
      "24076    -0.520681       0.387669   0.164436           -0.547848      thanks\n",
      "11552    -0.503243       1.255138  -0.829106           -0.471195    graphics\n",
      "17609    -0.473431      -0.048886  -0.098170            0.554049       order\n",
      "5904     -0.442626      -0.218789  -0.277091            0.668053  christians\n",
      "22567    -0.819150      -0.875358   1.505895           -0.740853       space\n",
      "11399     0.070047      -0.540518  -0.623287            0.342882         god\n",
      "26270     0.040889      -0.499824  -0.103209            0.343859         who\n",
      "18240     0.205676      -0.463732  -0.107726           -0.023516      people\n",
      "11984     0.021412      -0.434086  -0.219325            0.241276          he\n",
      "11552    -0.503243       1.255138  -0.829106           -0.471195    graphics\n",
      "11399     0.070047      -0.540518  -0.623287            0.342882         god\n",
      "10376    -0.213978       0.808667  -0.528633           -0.372614        file\n",
      "20430     0.615363      -0.381235  -0.499915           -0.019723    religion\n",
      "12769    -0.341974       0.833419  -0.487571           -0.280146       image\n",
      "22567    -0.819150      -0.875358   1.505895           -0.740853       space\n",
      "24076    -0.520681       0.387669   0.164436           -0.547848      thanks\n",
      "7073      0.152511      -0.085347   0.204399           -0.534054       could\n",
      "9027     -0.080978       0.136793   0.134541           -0.505094         edu\n",
      "16793    -0.125253       0.433090  -0.018273           -0.483261        need\n",
      "Bigram most important words and weights\n",
      "        alt.atheism  comp.graphics  sci.space  talk.religion.misc  \\\n",
      "98723     -0.483092       0.848250  -0.373455           -0.424819   \n",
      "65546     -0.365939       0.209159  -0.069992           -0.105625   \n",
      "184243    -0.358017       0.047684   0.085078            0.118872   \n",
      "81950     -0.355354       0.653378  -0.330181           -0.315109   \n",
      "85804     -0.333294       0.290704  -0.063646           -0.053236   \n",
      "37174      0.418703      -0.495626  -0.478153            0.424471   \n",
      "162974     0.077185      -0.481140   0.075095            0.116918   \n",
      "167336    -0.211935      -0.386953   0.668258           -0.213206   \n",
      "165984    -0.281642      -0.385629   0.676826           -0.181212   \n",
      "117456    -0.161749      -0.324083   0.044374            0.153236   \n",
      "37174      0.418703      -0.495626  -0.478153            0.424471   \n",
      "163684     0.222634      -0.319455  -0.394481            0.259812   \n",
      "98723     -0.483092       0.848250  -0.373455           -0.424819   \n",
      "83190      0.362237      -0.009865  -0.371370           -0.085713   \n",
      "193317     0.346619      -0.228430  -0.369304            0.055082   \n",
      "98723     -0.483092       0.848250  -0.373455           -0.424819   \n",
      "51959     -0.292409       0.353680   0.021202           -0.377809   \n",
      "119245    -0.165959       0.100233   0.067774           -0.323660   \n",
      "7432      -0.177034       0.252494   0.067365           -0.320475   \n",
      "81950     -0.355354       0.653378  -0.330181           -0.315109   \n",
      "\n",
      "                words  \n",
      "98723     looking for  \n",
      "65546         for the  \n",
      "184243        want to  \n",
      "81950      in advance  \n",
      "85804   interested in  \n",
      "37174     cheers kent  \n",
      "162974       that the  \n",
      "167336      the space  \n",
      "165984       the moon  \n",
      "117456         of the  \n",
      "37174     cheers kent  \n",
      "163684      the bible  \n",
      "98723     looking for  \n",
      "83190         in this  \n",
      "193317        you are  \n",
      "98723     looking for  \n",
      "51959     does anyone  \n",
      "119245         on the  \n",
      "7432          able to  \n",
      "81950      in advance  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nivelaga\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def P4():\n",
    "#Unigram\n",
    "    cv = CountVectorizer()\n",
    "    train_CV = cv.fit_transform(train_data)\n",
    "\n",
    "    LR = LogisticRegression(penalty='l2',C=0.2)\n",
    "    LR.fit(train_CV,train_labels)\n",
    "\n",
    "    CoefficientMat_Inv = pd.DataFrame(LR.coef_.transpose())\n",
    "    #identify highest weight words by the top 5 words for each category independently\n",
    "    Top5Words = np.append(np.append(CoefficientMat_Inv[0].sort_values().head(5).index, CoefficientMat_Inv[1].sort_values().head(5).index),np.append(CoefficientMat_Inv[2].sort_values().head(5).index, CoefficientMat_Inv[3].sort_values().head(5).index))\n",
    "    Top5_4class = CoefficientMat_Inv.loc[Top5Words]\n",
    "    Top5_4class.columns = newsgroups_train.target_names\n",
    "    Top5_4class['words'] = pd.Series(cv.get_feature_names()).loc[Top5Words]\n",
    "    print \"Unigram most important words and weights\"\n",
    "    print Top5_4class\n",
    "#Bigram\n",
    "    cv = CountVectorizer(ngram_range=(2,2))\n",
    "    train_CV = cv.fit_transform(train_data)\n",
    "\n",
    "    LR = LogisticRegression(penalty='l2',C=0.2)\n",
    "    LR.fit(train_CV,train_labels)\n",
    "\n",
    "    CoefficientMat_Inv = pd.DataFrame(LR.coef_.transpose())\n",
    "    Top5Words = np.append(np.append(CoefficientMat_Inv[0].sort_values().head(5).index, CoefficientMat_Inv[1].sort_values().head(5).index),np.append(CoefficientMat_Inv[2].sort_values().head(5).index, CoefficientMat_Inv[3].sort_values().head(5).index))\n",
    "    Top5_4class = CoefficientMat_Inv.loc[Top5Words]\n",
    "    Top5_4class.columns = newsgroups_train.target_names\n",
    "    Top5_4class['words'] = pd.Series(cv.get_feature_names()).loc[Top5Words]\n",
    "    print \"Bigram most important words and weights\"\n",
    "    print Top5_4class\n",
    "P4()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The bigrams don't appear particularly informative. While the words selected from the unigram features appear to directly link to the categories, the bigram features don't seem informative towards one class or another at all. It is also interesting that some of the unigrams and bigrams are highly weighted in multiple categories - this could lead to model confusion and misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Try to improve the logistic regression classifier by passing a custom preprocessor to CountVectorizer. The preprocessing function runs on the raw text, before it is split into words by the tokenizer. Your preprocessor should try to normalize the input in various ways to improve generalization. For example, try lowercasing everything, replacing sequences of numbers with a single token, removing various other non-letter characters, and shortening long words. If you're not already familiar with regular expressions for manipulating strings, see https://docs.python.org/2/library/re.html, and re.sub() in particular. With your new preprocessor, how much did you reduce the size of the dictionary?\n",
    "\n",
    "For reference, I was able to improve dev F1 by 2 points.\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with no processing: 0.713\n",
      "F1 with processing: 0.6878\n",
      "Untransformed data shape: (2034, 26879)\n",
      "Accuracy with processing: 0.7219\n",
      "F1 with processing: 0.7003\n",
      "Transformed data shape: (2034, 19835)\n"
     ]
    }
   ],
   "source": [
    "#nltk gives predefined functions for text cleaning\n",
    "import nltk\n",
    "#stemming reduces dimensionality of words\n",
    "from nltk.stem.porter import *\n",
    "#can use an NLTK corpus to check if the word is an english word\n",
    "from nltk.corpus import words\n",
    "#string functions for manipulations outside of nltk\n",
    "import string \n",
    "#for model performance eval\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "### STUDENT START ###\n",
    "    #use the porter premade stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    #clear punctuation\n",
    "    s = ''.join(ch for ch in s if ch not in string.punctuation)\n",
    "    #replace numbers with numeric token\n",
    "    s = re.sub(\"\\d{2,10000}\", \"<NUMTOKEN>\", s)\n",
    "    #stem each word\n",
    "    s = ''.join(stemmer.stem(w) + \" \" for w in nltk.word_tokenize(s))\n",
    "    return s\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "def P5():\n",
    "    ### STUDENT START ###\n",
    "    cv = CountVectorizer()\n",
    "    train_CV = cv.fit_transform(pd.Series(train_data).apply(empty_preprocessor))\n",
    "    LR = LogisticRegression(penalty='l2',C=0.2)\n",
    "    LR.fit(train_CV,train_labels)\n",
    "    \n",
    "    dev_CV = cv.transform(pd.Series(dev_data).apply(empty_preprocessor))\n",
    "    print \"Accuracy with no processing: \" + str(round(accuracy_score(dev_labels, LR.predict(dev_CV)),4))\n",
    "    print \"F1 with processing: \" + str(round(f1_score(dev_labels, LR.predict(dev_CV),average='macro'),4))\n",
    "    print \"Untransformed data shape: \" + str(train_CV.shape)\n",
    "    \n",
    "    #reinitialize CV so that we don't have info from previous corpus\n",
    "    cv = CountVectorizer()\n",
    "    train_CV = cv.fit_transform(pd.Series(train_data).apply(better_preprocessor))\n",
    "    LR = LogisticRegression(penalty='l2',C=0.2)\n",
    "    LR.fit(train_CV,train_labels)\n",
    "    \n",
    "    dev_CV = cv.transform(pd.Series(dev_data).apply(better_preprocessor))\n",
    "    print \"Accuracy with processing: \" + str(round(accuracy_score(dev_labels, LR.predict(dev_CV)),4))\n",
    "    print \"F1 with processing: \" + str(round(f1_score(dev_labels, LR.predict(dev_CV),average='macro'),4))\n",
    "    print \"Transformed data shape: \" + str(train_CV.shape)\n",
    "    ### STUDENT END ###\n",
    "    \n",
    "\n",
    "P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: By removing punctuation, substituting a token for all numbers above 2 digits in length, and stemming all words, we improve accuracy about slightly more than 1% in the dev set. We improve dev set F1 score by about 1.2%. These changes reduce the features in the vectorizer from 26879 to 19835."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) The idea of regularization is to avoid learning very large weights (which are likely to fit the training data, but not generalize well) by adding a penalty to the total size of the learned weights. That is, logistic regression seeks the set of weights that minimizes errors in the training data AND has a small size. The default regularization, L2, computes this size as the sum of the squared weights (see P3, above). L1 regularization computes this size as the sum of the absolute values of the weights. The result is that whereas L2 regularization makes all the weights relatively small, L1 regularization drives lots of the weights to 0, effectively removing unimportant features.\n",
    "\n",
    "Train a logistic regression model using a \"l1\" penalty. Output the number of learned weights that are not equal to zero. How does this compare to the number of non-zero weights you get with \"l2\"? Now, reduce the size of the vocabulary by keeping only those features that have at least one non-zero weight and retrain a model using \"l2\".\n",
    "\n",
    "Make a plot showing accuracy of the re-trained model vs. the vocabulary size you get when pruning unused features by adjusting the C parameter.\n",
    "\n",
    "Note: The gradient descent code that trains the logistic regression model sometimes has trouble converging with extreme settings of the C parameter. Relax the convergence criteria by setting tol=.01 (the default is .0001).\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P6():\n",
    "    ### STUDENT START ###\n",
    "    # Keep this random seed here to make comparison easier.\n",
    "    np.random.seed(0)\n",
    "    #iterate over c values to generate variation in coefficient weights for charting\n",
    "    cVals = np.append(np.arange(0.1,1,step=.1), np.arange(1,5,step=1))\n",
    "    AccuracyVocabDF = pd.DataFrame(columns=['VocabSize','Accuracy'],index=cVals)\n",
    "    for c in cVals:\n",
    "        cv = CountVectorizer()\n",
    "        train_CV = cv.fit_transform(train_data)\n",
    "        LR = LogisticRegression(penalty='l1',C=c)\n",
    "        LR.fit(train_CV,train_labels)\n",
    "        coefDF = pd.DataFrame(LR.coef_.transpose())\n",
    "        AccuracyVocabDF.loc[c, 'VocabSize'] = len(coefDF[(coefDF[0] != 0) | (coefDF[1] != 0) | (coefDF[2] != 0) | (coefDF[3] != 0)])\n",
    "        NonZeroCoeffs = coefDF[(coefDF[0] != 0) | (coefDF[1] != 0) | (coefDF[2] != 0) | (coefDF[3] != 0)].index\n",
    "\n",
    "        LR = LogisticRegression(penalty='l2',tol=0.1)\n",
    "        LR.fit(train_CV[:,NonZeroCoeffs],train_labels)\n",
    "\n",
    "        dev_CV = cv.transform(pd.Series(dev_data).apply(better_preprocessor))\n",
    "        AccuracyVocabDF.loc[c, 'Accuracy'] = round(accuracy_score(dev_labels, LR.predict(dev_CV[:,NonZeroCoeffs])),4)\n",
    "\n",
    "    plt.plot(AccuracyVocabDF.VocabSize,AccuracyVocabDF.Accuracy, linestyle='None', marker='*')\n",
    "    plt.title('Accuracy versus Non-Zero Coefficient weights: L2 After L1 Regularization')\n",
    "    plt.xlabel('Non-Zero Coefficient Weights')\n",
    "    plt.ylabel('Dev Set Accuracy')\n",
    "    \n",
    "\n",
    "    ### STUDENT END ###\n",
    "P6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Use the TfidfVectorizer -- how is this different from the CountVectorizer? Train a logistic regression model with C=100.\n",
    "\n",
    "Make predictions on the dev data and show the top 3 documents where the ratio R is largest, where R is:\n",
    "\n",
    "maximum predicted probability / predicted probability of the correct label\n",
    "\n",
    "What kinds of mistakes is the model making? Suggest a way to address one particular issue that you see.\n",
    "\n",
    "[4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "Three worst misclassifications in terms of R Ratio: \n",
      "    labels predictions    R_Ratio\n",
      "607      0           3  12.174166\n",
      "215      3           1   7.909815\n",
      "665      3           1   7.721977\n",
      "Text in Three worst Misclassifications: \n",
      "[u'\\nThe 24 children were, of course, killed by a lone gunman in a second story\\nwindow, who fired eight bullets in the space of two seconds...\\n'\n",
      " u'I am pleased to announce that a *revised version* of _The Easy-to-Read Book\\nof Mormon_ (former title: _Mormon\\'s Book_) by Lynn Matthews Anderson is now\\navailable through anonymous ftp (see information below). In addition to the\\nchange in title, the revised ETR BOM has been shortened by several pages\\n(eliminating many extraneous \"that\\'s\" and \"of\\'s\"), and many (minor) errors\\nhave been corrected. This release includes a simplified Joseph Smith Story,\\ntestimonies of the three and eight witnesses, and a \"Words-to-Know\"\\nglossary.\\n\\nAs with the previous announcement, readers are reminded that this is a\\nnot-for-profit endeavor. This is a copyrighted work, but people are welcome\\nto make *verbatim* copies for personal use. People can recuperate the\\nactual costs of printing (paper, copy center charges), but may not charge\\nanything for their time in making copies, or in any way realize a profit\\nfrom the use of this book. See the permissions notice in the book itself\\nfor the precise terms.\\n\\nNegotiations are currently underway with a Mormon publisher vis-a-vis the\\nprinting and distribution of bound books. (Sorry, I\\'m out of the wire-bound\\n\"first editions.\") I will make another announcement about the availability\\nof printed copies once everything has been worked out.\\n\\nFTP information: connect via anonymous ftp to carnot.itc.cmu.edu, then \"cd\\npub\" (you won\\'t see anything at all until you do).\\n\\n\"The Easy-to-Read Book of Mormon\" is currently available in postscript and\\nRTF (rich text format). (ASCII, LaTeX, and other versions can be made\\navailable; contact dba@andrew.cmu.edu for details.) You should be able to\\nprint the postscript file on any postscript printer (such as an Apple\\nLaserwriter); let dba know if you have any difficulties. (The postscript in\\nthe last release had problems on some printers; this time it should work\\nbetter.) RTF is a standard document interchange format that can be read in\\nby a number of word processors, including Microsoft Word for both the\\nMacintosh and Windows. If you don\\'t have a postscript printer, you may be\\nable to use the RTF file to print out a copy of the book.\\n\\n-r--r--r--  1 dba                   1984742 Apr 27 13:12 etrbom.ps\\n-r--r--r--  1 dba                   1209071 Apr 27 13:13 etrbom.rtf\\n\\nFor more information about how this project came about, please refer to my\\narticle in the current issue of _Sunstone_, entitled \"Delighting in\\nPlainness: Issues Surrounding a Simple Modern English Book of Mormon.\"\\n\\nSend all inquiries and comments to:\\n\\n    Lynn Matthews Anderson\\n    5806 Hampton Street\\n    Pittsburgh, PA 15206'\n",
      " u'Can anyone provide me a ftp site where I can obtain a online version\\nof the Book of Mormon. Please email the internet address if possible.']\n"
     ]
    }
   ],
   "source": [
    "def P7():\n",
    "    ### STUDENT START ###\n",
    "    tfidf = TfidfVectorizer()\n",
    "    train_tfidf = tfidf.fit_transform(train_data)\n",
    "    LR = LogisticRegression(C=100)\n",
    "    LR.fit(train_CV,train_labels)\n",
    "\n",
    "    dev_tfidf = tfidf.transform(dev_data)\n",
    "    predictions = LR.predict(dev_tfidf)\n",
    "    predictions_probs = LR.predict_proba(dev_tfidf)\n",
    "\n",
    "    Predictions_DF = pd.DataFrame([predictions,predictions_probs,dev_labels]).transpose()\n",
    "    Predictions_DF.columns = ['predictions','prediction_probabilities','labels']\n",
    "    Predictions_DF['MaxPredictionProb'] = Predictions_DF.prediction_probabilities.apply(np.amax)\n",
    "\n",
    "    Predictions_DF['LabelProbability'] = 0\n",
    "    for index, row in Predictions_DF.iterrows():\n",
    "        LabelInd = row['labels']\n",
    "        LabelProb = row['prediction_probabilities'][LabelInd]\n",
    "        Predictions_DF.loc[index, 'LabelProbability'] = LabelProb\n",
    "\n",
    "    Predictions_DF['R_Ratio'] = Predictions_DF.MaxPredictionProb / Predictions_DF.LabelProbability\n",
    "    print \"Categories: \" + str(newsgroups_train.target_names)\n",
    "    print \"Three worst misclassifications in terms of R Ratio: \"\n",
    "    print Predictions_DF.sort_values(by='R_Ratio',ascending=False).head(3)[['labels','predictions','R_Ratio']]\n",
    "    print \"Text in Three worst Misclassifications: \"\n",
    "    print np.asarray(dev_data)[Predictions_DF.sort_values(by='R_Ratio',ascending=False).head(3).index]\n",
    "    ### STUDENT END ###\n",
    "P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Two of the three worst misclassifications are predictions into label 1 (comp.graphics), when they actually belong to the last label (talk.religion.misc). Reading these texts, the problem is that there are several details about technology (FTP instructions, etc.) are included despite the religious keyword (\"Mormon\" specifically). To correct for these errors, we would want to increase the weight of the coefficients on words such as \"Mormon\", while reducing the weights on coefficients of words related to technology independently. I would consider replacing keywords relating to technology with a representative token (similar to the number token used previously). In the TF-IDF methodology, this would increase the document frequency of each individual technology word, so the weight for a word like \"ASCII\" or \"FTP\" wouldn't be so independently large and able to collectively change the classification from religion to technology (or at least, would shift the R Ratio downwards)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) EXTRA CREDIT\n",
    "\n",
    "Try implementing one of your ideas based on your error analysis. Use logistic regression as your underlying model.\n",
    "\n",
    "- [1 pt] for a reasonable attempt\n",
    "- [2 pts] for improved performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
